/**
 * Multimodal Training Types - Rich Media Communication for Academy
 * ================================================================
 * 
 * Extends ChatParticipant model to support video, audio, images, screen sharing
 * and other media types for richer Academy training experiences.
 * 
 * Users can:
 * - Share video of themselves explaining concepts
 * - Send audio recordings of pronunciations, explanations
 * - Upload images, diagrams, screenshots for analysis
 * - Stream their screen while working through problems
 * - Share documents, code files, data sets
 * 
 * Personas can:
 * - Analyze shared media and respond appropriately
 * - Generate their own media (screenshots, diagrams, code)
 * - Participate in video calls, voice chats
 * - Share their "screen" (generated interfaces, visualizations)
 * 
 * Architecture:
 * - Builds on existing ChatParticipant model
 * - Uses ArtifactsDaemon for media storage
 * - Real-time media streaming through WebRTC/WebSocket
 * - AI analysis of media content for learning insights
 */

import { AcademyParams, AcademyResult } from '../../shared/AcademyTypes';
import { ChatParticipant, ChatMessage, TrainingMessage } from '../chat-training/shared/ChatTrainingTypes';

// ========================
// Multimodal ChatParticipant Extension
// ========================

export interface MultimodalChatParticipant extends ChatParticipant {
  // Media capabilities
  mediaCapabilities: MediaCapabilities;
  
  // Current media state
  activeMediaStreams: ActiveMediaStream[];
  sharedMedia: SharedMediaItem[];
  
  // Media preferences
  mediaPreferences: MediaPreferences;
  
  // Analysis capabilities (for AI personas)
  mediaAnalysisCapabilities?: MediaAnalysisCapabilities;
  
  // Generation capabilities (for AI personas)
  mediaGenerationCapabilities?: MediaGenerationCapabilities;
}

export interface MediaCapabilities {
  // Input capabilities
  canReceiveVideo: boolean;
  canReceiveAudio: boolean;
  canReceiveImages: boolean;
  canReceiveDocuments: boolean;
  canReceiveScreenShare: boolean;
  
  // Output capabilities
  canSendVideo: boolean;                 // Can generate/stream video
  canSendAudio: boolean;                 // Can generate/stream audio
  canSendImages: boolean;                // Can generate/create images
  canSendDocuments: boolean;             // Can generate documents
  canShareScreen: boolean;               // Can share screen/interface
  
  // Real-time capabilities
  supportsLiveVideo: boolean;            // Real-time video communication
  supportsLiveAudio: boolean;            // Real-time audio communication
  supportsScreenStreaming: boolean;      // Real-time screen sharing
  
  // Processing capabilities
  canAnalyzeMedia: boolean;              // Can analyze received media
  realTimeProcessing: boolean;           // Can process media in real-time
  batchProcessing: boolean;              // Can process media offline
  
  // Quality settings
  videoQualityLevels: VideoQuality[];
  audioQualityLevels: AudioQuality[];
  processingLatency: number;             // Expected processing latency (ms)
}

export interface ActiveMediaStream {
  streamId: string;
  streamType: 'video' | 'audio' | 'screen_share' | 'document_share';
  
  // Source information
  sourceParticipant: string;             // Who is sharing
  targetParticipants: string[];          // Who can see/hear it
  
  // Stream configuration
  quality: MediaQuality;
  realTime: boolean;                     // Is this live streaming
  interactive: boolean;                  // Can viewers interact
  
  // Stream state
  status: 'starting' | 'active' | 'paused' | 'ending' | 'ended';
  startTime: number;
  duration?: number;                     // For recorded streams
  
  // Stream metadata
  description?: string;                  // What this stream is about
  learningContext?: string;              // Learning objective
  tags: string[];                        // Categorization tags
  
  // Real-time features
  liveAnalysis: boolean;                 // Analyze stream in real-time
  liveTranscription: boolean;            // Transcribe audio in real-time
  liveAnnotation: boolean;               // Allow real-time annotations
  
  // Storage
  recordStream: boolean;                 // Should stream be recorded
  artifactPath?: string;                 // Path to recorded stream
}

export interface SharedMediaItem {
  itemId: string;
  itemType: 'image' | 'video' | 'audio' | 'document' | 'code' | 'data' | 'interactive';
  
  // Content information
  title: string;
  description: string;
  originalFilename?: string;
  mimeType: string;
  fileSize: number;                      // bytes
  
  // Storage
  artifactPath: string;                  // Stored in ArtifactsDaemon
  thumbnailPath?: string;                // Preview/thumbnail
  metadata: MediaMetadata;
  
  // Upload/Share context
  sharedBy: string;                      // Participant who shared
  sharedAt: number;                      // Timestamp
  shareContext: ShareContext;
  
  // Processing results
  analysisResults?: MediaAnalysisResult[];
  transcription?: TranscriptionResult;
  extractedContent?: ExtractedContent;
  
  // Learning integration
  learningValue: number;                 // 0-1 learning value assessment
  relatedObjectives: string[];           // Learning objectives this supports
  suggestedUsage: string[];              // How this could be used in training
  
  // Interaction tracking
  viewedBy: ParticipantView[];          // Who has viewed this
  discussionGenerated: boolean;          // Did this generate discussion
  questionsRaised: string[];            // Questions this media raised
}

// ========================
// Media Analysis Types
// ========================

export interface MediaAnalysisCapabilities {
  // Visual analysis
  imageRecognition: boolean;             // Can recognize objects in images
  faceRecognition: boolean;              // Can recognize faces/people
  textExtraction: boolean;               // Can extract text from images/video
  sceneUnderstanding: boolean;           // Can understand visual scenes
  
  // Audio analysis
  speechRecognition: boolean;            // Can transcribe speech
  speakerIdentification: boolean;        // Can identify different speakers
  emotionDetection: boolean;             // Can detect emotional tone
  soundClassification: boolean;          // Can classify non-speech sounds
  
  // Video analysis
  actionRecognition: boolean;            // Can recognize actions in video
  objectTracking: boolean;               // Can track objects across frames
  sceneSegmentation: boolean;            // Can segment video into scenes
  
  // Document analysis
  documentParsing: boolean;              // Can parse document structure
  codeAnalysis: boolean;                 // Can analyze code files
  dataAnalysis: boolean;                 // Can analyze data files
  
  // Contextual analysis
  learningAnalysis: boolean;             // Can assess learning content
  instructionalDesign: boolean;          // Can evaluate instructional quality
  accessibilityAnalysis: boolean;        // Can assess accessibility
  
  // Real-time capabilities
  liveAnalysis: boolean;                 // Can analyze media in real-time
  streamingAnalysis: boolean;            // Can analyze streaming media
  interactiveAnalysis: boolean;          // Can analyze interactive content
}

export interface MediaAnalysisResult {
  analysisId: string;
  analysisType: string;                  // Type of analysis performed
  timestamp: number;
  
  // Analysis results
  confidence: number;                    // 0-1 confidence in results
  results: Record<string, any>;         // Structured analysis results
  insights: string[];                    // Human-readable insights
  
  // Learning-specific analysis
  educationalValue: number;              // 0-1 educational value
  complexityLevel: number;               // 0-1 complexity assessment
  prerequisiteKnowledge: string[];       // Knowledge needed to understand
  learningObjectives: string[];          // What this could teach
  
  // Content categorization
  topics: string[];                      // Topics covered
  skills: string[];                      // Skills demonstrated/required
  domains: string[];                     // Knowledge domains
  
  // Quality assessment
  clarity: number;                       // 0-1 how clear the content is
  completeness: number;                  // 0-1 how complete the content is
  accuracy: number;                      // 0-1 estimated accuracy
  
  // Recommendations
  improvementSuggestions: string[];
  followUpQuestions: string[];
  relatedResources: string[];
  
  // Technical metadata
  processingTime: number;                // ms to complete analysis
  resourcesUsed: ResourceUsage;
  analysisMethod: string;                // Method/model used
}

export interface MediaGenerationCapabilities {
  // Visual generation
  canGenerateImages: boolean;            // Can create images
  canGenerateDiagrams: boolean;          // Can create diagrams/charts
  canGenerateUI: boolean;                // Can create user interfaces
  canGenerateCode: boolean;              // Can create code visualizations
  
  // Audio generation
  canGenerateSpeech: boolean;            // Can create speech/narration
  canGenerateMusic: boolean;             // Can create background music
  canGenerateSoundEffects: boolean;      // Can create sound effects
  
  // Video generation
  canGenerateVideo: boolean;             // Can create video content
  canGenerateAnimations: boolean;        // Can create animated content
  canGenerateScreencasts: boolean;       // Can create screen recordings
  
  // Document generation
  canGenerateDocuments: boolean;         // Can create formatted documents
  canGeneratePresentations: boolean;     // Can create slide presentations
  canGenerateReports: boolean;           // Can create analysis reports
  
  // Interactive generation
  canGenerateInteractives: boolean;      // Can create interactive content
  canGenerateSimulations: boolean;       // Can create simulations
  canGenerateGames: boolean;             // Can create learning games
  
  // Real-time generation
  liveGeneration: boolean;               // Can generate content in real-time
  adaptiveGeneration: boolean;           // Can adapt content based on feedback
  collaborativeGeneration: boolean;      // Can co-create with humans
  
  // Quality settings
  generationQuality: 'draft' | 'good' | 'high' | 'production';
  generationSpeed: 'slow' | 'medium' | 'fast' | 'real_time';
  resourceRequirements: ResourceRequirements;
}

// ========================
// Multimodal Messages
// ========================

export interface MultimodalTrainingMessage extends TrainingMessage {
  // Media attachments
  mediaAttachments: MediaAttachment[];
  
  // Media references
  referencedMedia: string[];             // IDs of shared media being discussed
  generatedMedia: string[];              // Media generated in response
  
  // Multimodal content
  hasVisualComponent: boolean;           // Message has visual elements
  hasAudioComponent: boolean;            // Message has audio elements
  hasInteractiveComponent: boolean;      // Message has interactive elements
  
  // Cross-modal correlation
  textMediaCorrelation: TextMediaCorrelation[];
  
  // Real-time coordination
  synchronizedMedia: SynchronizedMediaEvent[];
  
  // Response generation
  suggestedMediaResponse: MediaResponseSuggestion[];
}

export interface MediaAttachment {
  attachmentId: string;
  attachmentType: 'image' | 'video' | 'audio' | 'document' | 'code' | 'interactive';
  
  // Content reference
  mediaItemId?: string;                  // Reference to SharedMediaItem
  inlineContent?: InlineMediaContent;    // Small inline content
  streamReference?: string;              // Reference to active stream
  
  // Attachment context
  purpose: 'illustration' | 'example' | 'reference' | 'exercise' | 'assessment' | 'discussion';
  importance: 'primary' | 'supporting' | 'optional';
  
  // Learning integration
  learningObjective?: string;
  skillDemonstration?: string;
  prerequisiteForUnderstanding: boolean;
  
  // Interaction expectations
  expectsResponse: boolean;              // Does this expect a response
  expectsAnalysis: boolean;              // Should this be analyzed
  expectsDiscussion: boolean;            // Should this be discussed
  
  // Accessibility
  altText?: string;                      // Alternative text description
  transcription?: string;                // Audio/video transcription
  captioning?: CaptioningInfo;           // Video captioning information
}

export interface TextMediaCorrelation {
  textSegment: string;                   // Part of text message
  mediaReference: string;                // Referenced media
  correlationType: 'describes' | 'references' | 'explains' | 'questions' | 'analyzes';
  
  // Correlation strength
  relevance: number;                     // 0-1 how relevant
  specificity: number;                   // 0-1 how specific the reference
  
  // Learning value
  clarifies: boolean;                    // Does media clarify text
  supplements: boolean;                  // Does media supplement text
  contradicts: boolean;                  // Does media contradict text
  
  // Timing
  sequencing: 'before' | 'during' | 'after'; // When to view media relative to text
  duration?: number;                     // How long to focus on media
}

// ========================
// Real-Time Media Integration
// ========================

export interface LiveMediaSession {
  sessionId: string;
  trainingSessionId: string;             // Associated training session
  
  // Session configuration
  mediaTypes: MediaType[];               // Active media types
  participants: LiveMediaParticipant[];
  
  // Real-time features
  liveAnalysis: boolean;                 // Analyze media in real-time
  liveTranscription: boolean;            // Transcribe audio in real-time
  liveFeedback: boolean;                 // Provide real-time feedback
  liveCollaboration: boolean;            // Enable collaborative media editing
  
  // Session state
  status: 'starting' | 'active' | 'paused' | 'ending' | 'ended';
  startTime: number;
  
  // Streaming configuration
  streamingQuality: StreamingQuality;
  streamingLatency: 'ultra_low' | 'low' | 'medium' | 'high';
  
  // Recording
  recordSession: boolean;
  recordingPath?: string;                // Path to session recording
  
  // Real-time events
  mediaEvents: LiveMediaEvent[];
  
  // Analytics
  engagementMetrics: LiveEngagementMetrics;
  learningMetrics: LiveLearningMetrics;
}

export interface LiveMediaParticipant {
  participantId: string;
  participantType: 'human' | 'persona';
  
  // Active capabilities
  activeInputs: MediaType[];             // What they're currently inputting
  activeOutputs: MediaType[];            // What they're currently outputting
  
  // Real-time state
  streamingQuality: StreamingQuality;
  connectionQuality: ConnectionQuality;
  latency: number;                       // Current latency in ms
  
  // Interaction state
  speaking: boolean;                     // Currently speaking
  sharing: boolean;                      // Currently sharing screen/media
  analyzing: boolean;                    // Currently analyzing media
  
  // Engagement indicators
  attention: number;                     // 0-1 attention level
  participation: number;                 // 0-1 participation level
  comprehension: number;                 // 0-1 apparent comprehension
  
  // Adaptive features
  adaptiveQuality: boolean;              // Adjust quality based on connection
  adaptiveContent: boolean;              // Adapt content based on comprehension
  personalizedExperience: boolean;       // Personalize based on preferences
}

export interface LiveMediaEvent {
  eventId: string;
  timestamp: number;
  eventType: 'media_start' | 'media_stop' | 'media_share' | 'interaction' | 'analysis_result';
  
  // Event details
  participant: string;                   // Who triggered the event
  mediaType: MediaType;
  eventData: Record<string, any>;
  
  // Learning context
  learningMoment: boolean;               // Is this a significant learning moment
  teachingOpportunity: boolean;          // Is this a teaching opportunity
  
  // Real-time processing
  requiresResponse: boolean;             // Does this need immediate response
  analysisTriggered: boolean;            // Did this trigger analysis
  
  // Event impact
  engagementImpact: number;              // -1 to 1 impact on engagement
  learningImpact: number;                // -1 to 1 impact on learning
  
  // Follow-up
  suggestedActions: string[];
  relatedEvents: string[];               // Related events in session
}

// ========================
// Command Types
// ========================

export class StartMultimodalSessionParams extends AcademyParams<{
  // Base session
  trainingSessionId: string;
  
  // Media configuration
  enabledMediaTypes: MediaType[];
  requiresVideo: boolean;
  requiresAudio: boolean;
  requiresScreenShare: boolean;
  
  // Real-time features
  enableLiveAnalysis: boolean;
  enableLiveTranscription: boolean;
  enableLiveFeedback: boolean;
  
  // Quality settings
  videoQuality: VideoQuality;
  audioQuality: AudioQuality;
  streamingLatency: 'ultra_low' | 'low' | 'medium' | 'high';
  
  // Recording
  recordSession: boolean;
  generateTranscripts: boolean;
  extractKeyMoments: boolean;
  
  // Accessibility
  enableCaptions: boolean;
  enableAudioDescriptions: boolean;
  enableSignLanguage: boolean;
  
  // Participants
  mediaParticipants: MediaParticipantConfig[];
}> {}

export class StartMultimodalSessionResult extends AcademyResult<{
  // Session info
  liveMediaSessionId: string;
  sessionUrls: MediaSessionUrls;
  
  // Real-time feeds
  videoStreamUrls: Record<string, string>;
  audioStreamUrls: Record<string, string>;
  screenShareUrls: Record<string, string>;
  
  // Analysis feeds
  liveAnalysisUrl?: string;
  transcriptionFeedUrl?: string;
  learningMetricsUrl?: string;
  
  // Participant access
  participantAccessInfo: ParticipantAccessInfo[];
  
  // Session configuration
  activeFeatures: string[];
  estimatedBandwidth: number;            // bytes/second
  expectedLatency: number;               // milliseconds
}> {}

export class ShareMediaParams extends AcademyParams<{
  // Media details
  mediaType: MediaType;
  mediaContent?: InlineMediaContent;     // For small inline media
  mediaFile?: string;                    // Path to media file
  streamId?: string;                     // For live streams
  
  // Share context
  shareContext: ShareContext;
  learningObjective?: string;
  
  // Processing options
  analyzeMedia: boolean;
  generateTranscription: boolean;
  extractContent: boolean;
  
  // Interaction options
  allowDiscussion: boolean;
  expectsResponse: boolean;
  
  // Target participants
  targetParticipants?: string[];         // Specific participants (default: all)
  
  // Accessibility
  includeAltText: boolean;
  includeCaptions: boolean;
  includeAudioDescription: boolean;
}> {}

export class ShareMediaResult extends AcademyResult<{
  // Media item created
  sharedMediaId: string;
  artifactPath: string;
  
  // Processing results
  analysisResults: MediaAnalysisResult[];
  transcriptionResult?: TranscriptionResult;
  extractedContent?: ExtractedContent;
  
  // Sharing results
  sharedWith: string[];                  // Participants who received it
  notificationsSent: string[];           // Notifications sent
  
  // Real-time results
  immediateReactions: ParticipantReaction[];
  questionsGenerated: string[];
  
  // Learning integration
  learningValue: number;                 // 0-1 assessed learning value
  relatedObjectives: string[];
  suggestedFollowUp: string[];
  
  // Analytics
  expectedEngagement: number;            // 0-1 predicted engagement
  recommendedUsage: string[];
}> {}

// ========================
// Supporting Types
// ========================

export type MediaType = 'video' | 'audio' | 'image' | 'screen_share' | 'document' | 'code' | 'interactive';

export interface VideoQuality {
  resolution: '480p' | '720p' | '1080p' | '4k';
  framerate: 15 | 30 | 60;
  bitrate: number;                       // kbps
  codec: 'h264' | 'vp8' | 'vp9' | 'av1';
}

export interface AudioQuality {
  sampleRate: 22050 | 44100 | 48000;
  bitrate: number;                       // kbps
  channels: 1 | 2;                       // mono or stereo
  codec: 'opus' | 'aac' | 'mp3';
}

export interface MediaQuality {
  video?: VideoQuality;
  audio?: AudioQuality;
  overall: 'low' | 'medium' | 'high' | 'ultra';
}

export interface StreamingQuality {
  video: VideoQuality;
  audio: AudioQuality;
  adaptiveBitrate: boolean;              // Can adjust quality based on connection
  bufferSize: number;                    // ms of buffering
}

export interface ShareContext {
  purpose: 'demonstration' | 'example' | 'exercise' | 'reference' | 'question' | 'assessment';
  urgency: 'low' | 'medium' | 'high';
  expectedEngagement: 'passive' | 'active' | 'interactive';
  
  // Learning context
  currentTopic: string;
  learningPhase: 'introduction' | 'exploration' | 'practice' | 'assessment';
  difficulty: number;                    // 0-1 content difficulty
  
  // Interaction expectations
  expectsQuestions: boolean;
  expectsDiscussion: boolean;
  expectsAnalysis: boolean;
  expectsResponse: boolean;
}

export interface InlineMediaContent {
  contentType: string;                   // MIME type
  content: string;                       // Base64 encoded content
  size: number;                          // bytes
  
  // Metadata
  description?: string;
  altText?: string;
  transcription?: string;
}

export interface TranscriptionResult {
  transcriptionId: string;
  text: string;
  confidence: number;                    // 0-1 overall confidence
  
  // Detailed transcription
  segments: TranscriptionSegment[];
  speakers: SpeakerInfo[];
  
  // Language information
  language: string;
  dialect?: string;
  
  // Processing metadata
  processingTime: number;                // ms
  method: 'automatic' | 'manual' | 'hybrid';
}

export interface TranscriptionSegment {
  startTime: number;                     // ms from beginning
  endTime: number;                       // ms from beginning
  text: string;
  confidence: number;                    // 0-1 confidence for this segment
  
  // Speaker information
  speakerId?: string;
  speakerConfidence?: number;            // 0-1 confidence in speaker ID
  
  // Linguistic analysis
  emotions?: string[];                   // Detected emotions
  intent?: string;                       // Detected intent
  sentiment?: 'positive' | 'negative' | 'neutral';
}

export interface ExtractedContent {
  contentType: 'text' | 'code' | 'data' | 'structured';
  extractedData: Record<string, any>;
  
  // Extraction quality
  completeness: number;                  // 0-1 how complete extraction is
  accuracy: number;                      // 0-1 estimated accuracy
  
  // Learning analysis
  concepts: string[];                    // Concepts found in content
  skills: string[];                      // Skills demonstrated/required
  knowledge: string[];                   // Knowledge contained
  
  // Structure
  hierarchy: ContentHierarchy;
  relationships: ContentRelationship[];
}

// Export all types
export type MultimodalData = 
  | MultimodalChatParticipant 
  | SharedMediaItem 
  | MediaAnalysisResult 
  | MultimodalTrainingMessage;

export type LiveMediaData = 
  | LiveMediaSession 
  | LiveMediaParticipant 
  | LiveMediaEvent 
  | StreamingQuality;

export type MediaProcessingData = 
  | MediaAnalysisCapabilities 
  | MediaGenerationCapabilities 
  | TranscriptionResult 
  | ExtractedContent;