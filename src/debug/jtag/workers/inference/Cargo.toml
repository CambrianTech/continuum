[package]
name = "inference-worker"
version = "0.1.0"
edition = "2021"
description = "Candle-based LLM inference worker with multi-adapter LoRA composition"

[dependencies]
# Candle ML framework
candle-core = "0.8"
candle-nn = "0.8"
candle-transformers = "0.8"

# HuggingFace Hub for model downloads
hf-hub = "0.4"

# Fast tokenization
tokenizers = "0.20"

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Async runtime (for socket handling)
tokio = { version = "1", features = ["full"] }

# Timing, UUIDs, and logging (required for JTAG protocol)
chrono = "0.4"
uuid = { version = "1.6", features = ["v4"] }

# Thread-safe primitives
lazy_static = "1.4"
once_cell = "1.19"

# Random number generation (for sampling)
rand = "0.8"

[features]
default = ["metal"]
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal"]
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]
accelerate = ["candle-core/accelerate", "candle-nn/accelerate", "candle-transformers/accelerate"]

[[bin]]
name = "inference-worker"
path = "src/main.rs"
