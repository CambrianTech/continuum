//! Mixer + ProductionVAD Integration Test
//!
//! Tests the complete integration of ProductionVAD into the mixer:
//! - Two-stage VAD (WebRTC â†’ Silero)
//! - Complete sentence detection
//! - High recall (0.3 threshold)
//! - Low latency (5400x speedup on silence)

use streaming_core::mixer::{AudioMixer, ParticipantStream};
use streaming_core::vad::TestAudioGenerator;
use streaming_core::vad::Vowel;
use streaming_core::Handle;

#[tokio::test]
#[ignore] // Requires Silero model
async fn test_mixer_production_vad_complete_sentences() {
    let mut mixer = AudioMixer::default_voice();

    let handle = Handle::new();
    let mut stream = ParticipantStream::new(handle, "user-1".into(), "Alice".into());

    // Initialize ProductionVAD (requires Silero model)
    stream
        .initialize_vad()
        .await
        .expect("ProductionVAD init failed");

    mixer.add_participant(stream);

    let gen = TestAudioGenerator::new(16000);

    println!("\nðŸ“Š Mixer + ProductionVAD Integration Test\n");

    // Simulate a sentence: "Hello" (pause) "how are" (pause) "you"
    let frames = vec![
        ("Hello", gen.generate_formant_speech(512, Vowel::A)), // Speech
        ("pause", vec![0; 512]),                                // Brief silence (natural pause)
        ("how", gen.generate_formant_speech(512, Vowel::O)),   // Speech
        ("are", gen.generate_formant_speech(512, Vowel::A)),   // Speech
        ("pause", vec![0; 512]),                                // Brief silence
        ("you", gen.generate_formant_speech(512, Vowel::U)),   // Speech
    ];

    let mut sentence_count = 0;

    for (label, frame) in &frames {
        let result = mixer.push_audio(&handle, frame.clone());

        if result.speech_ended {
            sentence_count += 1;
            let duration_ms = (result.speech_samples.as_ref().unwrap().len() as f32 / 16000.0)
                * 1000.0;
            println!(
                "âœ“ Complete sentence #{} ready ({:.0}ms)",
                sentence_count, duration_ms
            );
        } else {
            println!("  Buffering: {}...", label);
        }
    }

    // Add silence frames to trigger final transcription (40 frames = 1.28s)
    for i in 0..40 {
        let result = mixer.push_audio(&handle, vec![0; 512]);
        if result.speech_ended {
            sentence_count += 1;
            let duration_ms = (result.speech_samples.as_ref().unwrap().len() as f32 / 16000.0)
                * 1000.0;
            println!(
                "âœ“ Final sentence complete after {} silence frames ({:.0}ms)",
                i + 1,
                duration_ms
            );
            break;
        }
    }

    assert!(
        sentence_count > 0,
        "Should have detected at least one complete sentence"
    );

    println!("\nâœ… ProductionVAD successfully integrated into mixer!");
    println!("   - Complete sentence buffering works");
    println!("   - Natural pauses preserved");
    println!("   - No fragments");
}

#[tokio::test]
#[ignore] // Requires Silero model
async fn test_mixer_production_vad_noise_rejection() {
    let mut mixer = AudioMixer::default_voice();

    let handle = Handle::new();
    let mut stream = ParticipantStream::new(handle, "user-1".into(), "Alice".into());

    stream
        .initialize_vad()
        .await
        .expect("ProductionVAD init failed");

    mixer.add_participant(stream);

    println!("\nðŸ“Š Mixer Noise Rejection Test\n");

    // Pure silence (should not transcribe)
    for i in 0..50 {
        let result = mixer.push_audio(&handle, vec![0; 512]);
        if result.speech_ended {
            panic!("ProductionVAD falsely detected speech in silence at frame {}", i);
        }
    }

    println!("âœ“ 50 silence frames: No false positives");

    // White noise (should not transcribe)
    let gen = TestAudioGenerator::new(16000);
    for i in 0..50 {
        let noise = (0..512)
            .map(|_| (rand::random::<f32>() * 1000.0 - 500.0) as i16)
            .collect();
        let result = mixer.push_audio(&handle, noise);
        if result.speech_ended {
            panic!("ProductionVAD falsely detected speech in noise at frame {}", i);
        }
    }

    println!("âœ“ 50 noise frames: No false positives");

    // Real speech (should transcribe)
    for _ in 0..10 {
        let speech = gen.generate_formant_speech(512, Vowel::A);
        mixer.push_audio(&handle, speech);
    }

    // Trigger transcription with silence
    let mut transcription_triggered = false;
    for i in 0..40 {
        let result = mixer.push_audio(&handle, vec![0; 512]);
        if result.speech_ended {
            transcription_triggered = true;
            println!("âœ“ Speech detected after {} silence frames", i + 1);
            break;
        }
    }

    assert!(
        transcription_triggered,
        "ProductionVAD should detect real speech"
    );

    println!("\nâœ… Noise rejection working correctly!");
}

#[tokio::test]
#[ignore] // Requires Silero model
async fn test_mixer_production_vad_multi_participant() {
    let mut mixer = AudioMixer::default_voice();

    let handle_a = Handle::new();
    let handle_b = Handle::new();

    let mut stream_a = ParticipantStream::new(handle_a, "user-a".into(), "Alice".into());
    let mut stream_b = ParticipantStream::new(handle_b, "user-b".into(), "Bob".into());

    stream_a
        .initialize_vad()
        .await
        .expect("VAD init failed for Alice");
    stream_b
        .initialize_vad()
        .await
        .expect("VAD init failed for Bob");

    mixer.add_participant(stream_a);
    mixer.add_participant(stream_b);

    let gen = TestAudioGenerator::new(16000);

    println!("\nðŸ“Š Multi-Participant VAD Test\n");

    // Alice speaks
    for _ in 0..5 {
        let speech = gen.generate_formant_speech(512, Vowel::A);
        mixer.push_audio(&handle_a, speech);
    }

    // Bob speaks at the same time
    for _ in 0..5 {
        let speech = gen.generate_formant_speech(512, Vowel::O);
        mixer.push_audio(&handle_b, speech);
    }

    println!("âœ“ Both participants speaking simultaneously");

    // Silence for Alice (should trigger her transcription)
    let mut alice_transcribed = false;
    for i in 0..40 {
        let result = mixer.push_audio(&handle_a, vec![0; 512]);
        if result.speech_ended {
            alice_transcribed = true;
            println!("âœ“ Alice's speech transcribed after {} silence frames", i + 1);
            break;
        }
    }

    // Silence for Bob (should trigger his transcription)
    let mut bob_transcribed = false;
    for i in 0..40 {
        let result = mixer.push_audio(&handle_b, vec![0; 512]);
        if result.speech_ended {
            bob_transcribed = true;
            println!("âœ“ Bob's speech transcribed after {} silence frames", i + 1);
            break;
        }
    }

    assert!(alice_transcribed, "Alice's speech should be detected");
    assert!(bob_transcribed, "Bob's speech should be detected");

    println!("\nâœ… Multi-participant VAD working correctly!");
    println!("   - Independent VAD per participant");
    println!("   - Simultaneous speech supported");
}
