[package]
name = "streaming-core"
version.workspace = true
edition.workspace = true
description = "Universal streaming backbone for AI communication"

[features]
default = ["grpc"]
grpc = []

[dependencies]
# Async runtime
tokio.workspace = true
tokio-stream.workspace = true

# gRPC
tonic.workspace = true
prost.workspace = true

# Utilities
uuid.workspace = true
thiserror.workspace = true
tracing.workspace = true
tracing-subscriber.workspace = true
async-trait.workspace = true
parking_lot.workspace = true

# Serialization (for events)
serde.workspace = true
serde_json.workspace = true

# Async streaming for gRPC
async-stream = "0.3"

# WebSocket
tokio-tungstenite.workspace = true
futures-util.workspace = true
futures = "0.3"  # For VAD block_on in audio thread

# Random (for test audio generation)
rand.workspace = true

# Audio processing
hound = "3.5"  # WAV file reading/writing
once_cell = "1.19"  # Lazy static initialization
rubato = "0.15"  # High-quality audio resampling

# ML Inference (off main thread)
whisper-rs = "0.13"  # Whisper.cpp bindings for STT - runs on dedicated thread pool
ort.workspace = true  # ONNX Runtime for TTS models - uses workspace config with download-binaries

# Thread pool for blocking ML operations
rayon = "1.10"

# Base64 encoding (for audio over gRPC)
base64 = "0.22"

# N-dimensional arrays (for ONNX tensor I/O)
ndarray = "0.16"

# CPU count detection
num_cpus = "1.16"

# User directories (for model paths)
dirs = "5.0"

# TypeScript type generation
ts-rs.workspace = true

[build-dependencies]
tonic-build = "0.11"

[[bin]]
name = "streaming-core"
path = "src/main.rs"
