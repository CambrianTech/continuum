[package]
name = "inference-grpc"
version.workspace = true
edition.workspace = true
description = "gRPC inference server with Candle LLM backend"

[[bin]]
name = "inference-grpc"
path = "src/main.rs"

[dependencies]
# gRPC
tonic.workspace = true
prost.workspace = true
tokio.workspace = true
tokio-stream.workspace = true

# Candle ML framework
candle-core.workspace = true
candle-nn.workspace = true
candle-transformers.workspace = true

# Model loading
safetensors.workspace = true
hf-hub.workspace = true
tokenizers.workspace = true

# Serialization
serde.workspace = true
serde_json.workspace = true

# Utilities
once_cell.workspace = true
rand.workspace = true
half = "2.4"
dirs = "5.0"

# Logging
log = "0.4"
env_logger = "0.11"

[features]
default = ["metal"]
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal"]
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]

[build-dependencies]
tonic-build = "0.11"
