# Voice Streaming Architecture

## Overview

Voice chat infrastructure for real-time audio communication with AI personas. Everything is streaming, following the same pattern as vision but for audio.

## Implementation Status

| Component | Status | Notes |
|-----------|--------|-------|
| **Commands** | | |
| voice/start | âœ… Complete | Start session, get WebSocket URL |
| voice/stop | âœ… Complete | End session |
| voice/transcribe | âœ… Complete | STT via Rust Whisper (stub impl) |
| voice/synthesize | âœ… Complete | TTS via Rust adapters (stub impl) |
| **TypeScript** | | |
| VoiceGrpcClient | âœ… Complete | gRPC client to Rust worker |
| VoiceChatWidget | âœ… Complete | Browser widget with AudioWorklet |
| VoiceWebSocketHandler | âœ… Complete | Routes audio â†’ STT â†’ Chat â†’ PersonaUser â†’ TTS â†’ audio |
| **Rust Worker** | | |
| voice.proto | âœ… Complete | gRPC service definition |
| VoiceService gRPC | âœ… Complete | Implements all RPC methods |
| TTSAdapterRegistry | âœ… Complete | 5 adapters registered |
| TTS Adapters | ğŸ”§ Stubs | Kokoro, Fish, F5, StyleTTS2, XTTS (stubs return silence) |
| STT (Whisper) | ğŸ”§ Stub | Returns placeholder text |

**Next Steps:**
1. ~~Wire VoiceWebSocketHandler to PersonaUser~~ âœ… Done
2. ~~Test full end-to-end voice conversation~~ âœ… Done (verified: transcribe â†’ chat â†’ synthesize flow works)
3. Implement real Kokoro TTS inference (candle-based, currently returns silence)
4. Implement real Whisper STT inference (candle-whisper, currently returns placeholder)
5. Start the streaming-core Rust worker as part of npm start (currently manual: `cd workers/streaming-core && cargo run`)

## Architecture Philosophy

**Same Pattern as Vision**: Models can support voice natively OR use adapters.
- Native voice: Model handles audio directly (future SOTA models)
- Adapter path: STT â†’ text â†’ model â†’ text â†’ TTS

**TypeScript for Portability, Rust for Speed**:
- Commands (`voice/start`, `voice/transcribe`, `voice/synthesize`) in TypeScript
- Heavy lifting (inference, audio processing) in Rust workers
- gRPC between TypeScript and Rust (port 50052)

## Component Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            BROWSER                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VoiceChatWidget                                                        â”‚
â”‚  â”œâ”€â”€ AudioWorklet (capture/playback)                                    â”‚
â”‚  â”œâ”€â”€ WebSocket connection to server                                     â”‚
â”‚  â””â”€â”€ UI controls (mute, speaker selection)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ WebSocket (audio frames)
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            SERVER                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VoiceWebSocketHandler                                                  â”‚
â”‚  â”œâ”€â”€ Receives audio frames from browser                                 â”‚
â”‚  â”œâ”€â”€ Calls voice/transcribe command                                     â”‚
â”‚  â”œâ”€â”€ Routes text to PersonaInbox                                        â”‚
â”‚  â”œâ”€â”€ Calls voice/synthesize command                                     â”‚
â”‚  â””â”€â”€ Streams audio back to browser                                      â”‚
â”‚                                                                         â”‚
â”‚  Commands:                                                              â”‚
â”‚  â”œâ”€â”€ voice/start    - Start voice session, get WebSocket URL            â”‚
â”‚  â”œâ”€â”€ voice/stop     - End voice session                                 â”‚
â”‚  â”œâ”€â”€ voice/transcribe - STT via Rust Whisper                            â”‚
â”‚  â””â”€â”€ voice/synthesize - TTS via Rust Kokoro/etc                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ gRPC (port 50052)
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RUST STREAMING-CORE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VoiceService (gRPC)                                                    â”‚
â”‚  â”œâ”€â”€ Synthesize     - Batch TTS                                         â”‚
â”‚  â”œâ”€â”€ SynthesizeStream - Streaming TTS                                   â”‚
â”‚  â”œâ”€â”€ Transcribe     - STT                                               â”‚
â”‚  â””â”€â”€ ListAdapters   - Available TTS engines                             â”‚
â”‚                                                                         â”‚
â”‚  TTS Adapters (tts.rs):                                                 â”‚
â”‚  â”œâ”€â”€ KokoroAdapter      - #1 on TTS Arena (80.9% win rate)              â”‚
â”‚  â”œâ”€â”€ FishSpeechAdapter  - Natural conversational                        â”‚
â”‚  â”œâ”€â”€ F5TTSAdapter       - Zero-shot voice cloning                       â”‚
â”‚  â”œâ”€â”€ StyleTTS2Adapter   - Style transfer                                â”‚
â”‚  â””â”€â”€ XTTSv2Adapter      - Multi-lingual                                 â”‚
â”‚                                                                         â”‚
â”‚  STT (Whisper via candle):                                              â”‚
â”‚  â””â”€â”€ Models: tiny, base, small, medium, large                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Voice Flow (Real-time Chat)

```
User speaks â†’ Mic â†’ AudioWorklet â†’ WebSocket â†’ Server
                                                  â”‚
                                                  â–¼
                                    voice/transcribe (Whisper STT)
                                                  â”‚
                                                  â–¼
                                    Text to PersonaInbox
                                                  â”‚
                                                  â–¼
                                    PersonaUser generates response
                                                  â”‚
                                                  â–¼
                                    voice/synthesize (Kokoro TTS)
                                                  â”‚
                                                  â–¼
                        Server â†’ WebSocket â†’ AudioWorklet â†’ Speaker
```

## Commands

### voice/start

Start a voice chat session.

```bash
./jtag voice/start --room="general"
# Returns: { handle: "abc-123", wsUrl: "ws://localhost:3000/ws/voice?handle=abc-123" }

./jtag voice/start --room="general" --model="llama3.2:3b" --voice="amy"
```

**Parameters:**
- `room` (optional): Room ID or name, defaults to "general"
- `model` (optional): LLM model for responses
- `voice` (optional): TTS voice ID

**Returns:**
- `handle`: Session UUID for correlation
- `wsUrl`: WebSocket URL for audio streaming
- `roomId`: Resolved room ID

### voice/stop

End a voice chat session.

```bash
./jtag voice/stop --handle="abc-123"
```

### voice/transcribe

Transcribe audio to text (STT).

```bash
./jtag voice/transcribe --audio="<base64-pcm-data>"
# Returns: { text: "Hello world", language: "en", confidence: 0.95 }

./jtag voice/transcribe --audio="<base64>" --language="es" --model="small"
```

**Parameters:**
- `audio` (required): Base64-encoded PCM 16-bit, 16kHz mono audio
- `format` (optional): Audio format hint ("pcm16", "wav", "opus")
- `language` (optional): Language hint or "auto" (default: auto-detect)
- `model` (optional): Whisper model size ("tiny", "base", "small", "medium", "large")

**Returns:**
- `text`: Transcribed text
- `language`: Detected language code
- `confidence`: Confidence score (0-1)
- `segments`: Word-level timestamps [{word, start, end}]

### voice/synthesize

Synthesize text to speech (TTS).

```bash
./jtag voice/synthesize --text="Hello, how can I help you?"
# Returns: { audio: "<base64-pcm>", sampleRate: 24000, duration: 1.8, adapter: "kokoro" }

./jtag voice/synthesize --text="Welcome!" --voice="amy" --adapter="kokoro" --speed=1.1
```

**Parameters:**
- `text` (required): Text to synthesize
- `voice` (optional): Voice ID (adapter-specific)
- `adapter` (optional): TTS adapter ("kokoro", "fish-speech", "f5-tts", "styletts2", "xtts-v2")
- `speed` (optional): Speed multiplier (0.5-2.0, default 1.0)
- `sampleRate` (optional): Output sample rate (default: adapter's native rate, usually 24000)
- `format` (optional): Output format ("pcm16", "wav", "opus")
- `stream` (optional): Return streaming handle instead of complete audio

**Returns:**
- `audio`: Base64-encoded audio (if stream=false)
- `handle`: Streaming handle (if stream=true)
- `sampleRate`: Actual sample rate
- `duration`: Audio duration in seconds
- `adapter`: TTS adapter that was used

## TTS Adapters

All adapters follow the `TTSAdapter` trait in `/workers/streaming-core/src/tts.rs`:

| Adapter | Quality Rank | Specialty | Native Sample Rate |
|---------|--------------|-----------|-------------------|
| Kokoro | #1 (80.9%) | Best overall quality | 24000 Hz |
| Fish Speech | Good | Natural conversational | 24000 Hz |
| F5-TTS | Good | Zero-shot voice cloning | 24000 Hz |
| StyleTTS2 | Good | Style transfer | 24000 Hz |
| XTTSv2 | Moderate | Multi-lingual support | 22050 Hz |

Rankings from [TTS Arena](https://huggingface.co/spaces/TTS-Arena/tts-arena-leaderboard) as of January 2026.

### Adapter Trait

```rust
#[async_trait]
pub trait TTSAdapter: Send + Sync {
    fn name(&self) -> &'static str;
    fn description(&self) -> &'static str;
    fn supports_voice_cloning(&self) -> bool;
    fn available_speakers(&self) -> Vec<String>;
    fn default_sample_rate(&self) -> u32;

    async fn load(&mut self) -> Result<(), TTSError>;
    async fn unload(&mut self) -> Result<(), TTSError>;
    fn is_loaded(&self) -> bool;

    async fn synthesize(&self, text: &str, params: &TTSParams) -> Result<Vec<i16>, TTSError>;
    async fn synthesize_stream(&self, text: &str, params: &TTSParams) -> Result<TTSAudioStream, TTSError>;
}
```

## Integration with PersonaUser

Voice follows the same capability-based routing as vision:

1. **AICapabilityRegistry** tracks `audio-input` and `audio-output` capabilities per model
2. **Models with native voice** (future): Audio routed directly to model
3. **Models without native voice**: STT â†’ text â†’ model â†’ text â†’ TTS

### Capability Flow

```typescript
// Check if model supports native voice
const hasNativeVoice = AICapabilityRegistry.hasCapability(modelId, 'audio-input');

if (hasNativeVoice) {
  // Send audio directly to model
  response = await AIProviderDaemon.generateText({
    content: [{ type: 'audio', data: audioBase64 }],
    // ...
  });
} else {
  // Use adapter path
  const text = await Commands.execute('voice/transcribe', { audio: audioBase64 });
  const response = await PersonaInbox.process(text);
  const audio = await Commands.execute('voice/synthesize', { text: response });
}
```

## Streaming Core Architecture

The Rust worker (`/workers/streaming-core/`) handles all heavy audio processing:

```
/workers/streaming-core/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs          # Module exports
â”‚   â”œâ”€â”€ tts.rs          # TTS adapters (Kokoro, Fish, F5, StyleTTS2, XTTSv2)
â”‚   â”œâ”€â”€ ws_audio.rs     # WebSocket audio adapters
â”‚   â”œâ”€â”€ frame.rs        # Audio/Video frame types
â”‚   â”œâ”€â”€ ring.rs         # Lock-free ring buffers
â”‚   â”œâ”€â”€ event.rs        # Event bus
â”‚   â”œâ”€â”€ pipeline.rs     # Processing pipeline
â”‚   â””â”€â”€ stage.rs        # Pipeline stages (STT, TTS, VAD, LLM)
â”œâ”€â”€ proto/
â”‚   â””â”€â”€ voice.proto     # gRPC service definition
â””â”€â”€ Cargo.toml
```

### Zero-Copy Design

- Ring buffers hold data, pass SlotRef (8 bytes)
- GPU textures stay on GPU, pass texture ID
- Only copy at boundaries (encode/decode)

### Pipeline Model

```
InputAdapter -> [VAD] -> [STT] -> [LLM] -> [TTS] -> OutputAdapter
     â†“            â†“        â†“        â†“        â†“           â†“
  EventBus â† â† Events (Started, Progress, FrameReady, Completed)
```

## Files

### Commands
- `/commands/voice/start/` - Start voice session
- `/commands/voice/stop/` - Stop voice session
- `/commands/voice/transcribe/` - STT command
- `/commands/voice/synthesize/` - TTS command

### Client
- `/system/core/services/VoiceGrpcClient.ts` - gRPC client for Rust worker

### Server
- `/system/voice/server/VoiceWebSocketHandler.ts` - WebSocket handler for audio â†’ STT â†’ chat â†’ TTS â†’ audio

### Browser
- `/widgets/voice-chat/VoiceChatWidget.ts` - Browser widget
- `/browser/audio/audio-capture-processor.ts` - AudioWorklet capture
- `/browser/audio/audio-playback-processor.ts` - AudioWorklet playback

### Rust Worker
- `/workers/streaming-core/src/tts.rs` - TTS adapters (Kokoro, Fish, F5, StyleTTS2, XTTSv2)
- `/workers/streaming-core/src/voice_service.rs` - gRPC VoiceService implementation
- `/workers/streaming-core/src/ws_audio.rs` - WebSocket audio handling
- `/workers/streaming-core/proto/voice.proto` - gRPC service definition
- `/workers/streaming-core/src/stage.rs` - Pipeline stages (VAD, STT, TTS, LLM)

## Testing

```bash
# Verify TypeScript compiles
npm run build:ts

# Test TTS adapters (Rust)
cd workers/streaming-core && cargo test tts

# Test voice commands (requires running system)
npm start
./jtag voice/synthesize --text="Hello world"
./jtag voice/transcribe --audio="<base64-pcm-data>"

# Full voice chat flow
./jtag voice/start --room="general"
# Open browser, speak, verify AI responds with voice
./jtag voice/stop --handle="<handle>"
```

## Future Work

1. **Native Voice Models**: As SOTA models add native audio I/O, route directly
2. **Voice Cloning**: Use F5-TTS or XTTSv2 for persona-specific voices
3. **Emotion Detection**: Analyze voice for emotional context in RAG
4. **Multi-speaker**: Track multiple speakers in group calls
5. **Phone Integration**: Twilio/WebRTC adapters for phone-based voice chat
