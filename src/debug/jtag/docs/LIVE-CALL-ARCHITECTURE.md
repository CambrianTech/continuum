# Live Call Architecture

## Philosophy: Game Engine, Not Web Dev

**Core principles (non-negotiable):**
1. **Handles, not copies** - Pass IDs to the deepest layer, never copy audio/video buffers
2. **Command buffers** - Batch operations, submit atomically, execute on dedicated thread
3. **Zero-copy pipeline** - Audio/video data stays in native memory, JS only holds handles
4. **Resource pools** - Pre-allocate, reuse, never allocate per-frame
5. **Separation of concerns** - Signaling vs data transport are different systems

Reference: [bgfx](https://github.com/bkaradzic/bgfx) handle architecture

---

## Handle Types

```rust
// All handles are u32 indices into typed pools
// Generation bits prevent use-after-free

pub struct AudioStreamHandle(u32);   // Live audio input/output stream
pub struct AudioMixHandle(u32);      // Mixed output for a participant
pub struct VideoFrameHandle(u32);    // Video frame in GPU/shared memory
pub struct CallHandle(u32);          // Active call instance
pub struct ParticipantHandle(u32);   // Participant in a call
pub struct TransportHandle(u32);     // WebRTC/WebSocket connection
```

**Handle lifecycle:**
```
create() â†’ Handle    // Allocate from pool, return handle
use(Handle)          // Operations reference by handle
destroy(Handle)      // Return to pool, increment generation
```

---

## Architecture Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        APPLICATION LAYER                         â”‚
â”‚  Commands: live/start, live/join, live/mute, etc.               â”‚
â”‚  Widget: LiveWidget (UI only, no audio processing)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ Commands (signaling only)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CALL MANAGER (TypeScript)                   â”‚
â”‚  - Call state machine                                           â”‚
â”‚  - Participant tracking                                         â”‚
â”‚  - Handle bookkeeping (does NOT touch audio/video data)         â”‚
â”‚  - Routes signaling between browser â†” server â†” peers           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ Handles + Commands
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   STREAMING CORE (Rust Worker)                   â”‚
â”‚  - Owns ALL audio/video buffers (zero JS copies)                â”‚
â”‚  - Audio capture â†’ AudioStreamHandle                            â”‚
â”‚  - Audio mixing â†’ AudioMixHandle                                â”‚
â”‚  - Video encoding/decoding                                      â”‚
â”‚  - TTS injection (AI voice)                                     â”‚
â”‚  - Command buffer execution                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ Raw packets
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TRANSPORT LAYER                             â”‚
â”‚  - WebRTC DataChannel (P2P when possible)                       â”‚
â”‚  - WebSocket fallback (server relay)                            â”‚
â”‚  - Handles only carry packets, never decode                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Audio Pipeline (Zero-Copy)

### Browser â†’ Rust (Mic Capture)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    SharedArrayBuffer    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AudioWorklet â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ streaming-core   â”‚
â”‚ (capture)    â”‚    (ring buffer)        â”‚ (Rust worker)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                          â”‚
       â”‚ No copies!                               â”‚
       â”‚ Worklet writes directly                  â–¼
       â”‚ to shared memory              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                               â”‚ AudioStreamHandleâ”‚
       â”‚                               â”‚ (index into pool)â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**AudioWorklet (browser):**
```javascript
// processor.js - runs on audio thread
class CaptureProcessor extends AudioWorkletProcessor {
  constructor() {
    // Get SharedArrayBuffer from main thread
    this.ringBuffer = new Float32Array(sharedArrayBuffer);
    this.writePtr = 0;
  }

  process(inputs) {
    const input = inputs[0][0]; // mono
    // Write directly to shared memory - NO COPY
    this.ringBuffer.set(input, this.writePtr);
    this.writePtr = (this.writePtr + input.length) % this.ringBuffer.length;
    return true;
  }
}
```

**Rust worker:**
```rust
// streaming-core/src/audio/capture.rs
pub struct AudioCaptureStream {
    shared_buffer: &'static [f32],  // Maps to SharedArrayBuffer
    read_ptr: AtomicUsize,
    handle: AudioStreamHandle,
}

impl AudioCaptureStream {
    pub fn read_samples(&self, out: &mut [f32]) -> usize {
        // Read from shared buffer - NO COPY from JS
        // Audio data never touched JavaScript heap
    }
}
```

### Rust â†’ Browser (Playback)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    SharedArrayBuffer    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ streaming-core   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ AudioWorklet â”‚
â”‚ (mixer output)   â”‚    (ring buffer)        â”‚ (playback)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Same pattern reversed - Rust writes, Worklet reads.

---

## Mixing Architecture

**Per-call mixer (Rust):**
```rust
pub struct CallMixer {
    call: CallHandle,
    inputs: Vec<AudioStreamHandle>,     // All participant streams
    outputs: HashMap<ParticipantHandle, AudioMixHandle>,  // Mix-minus per participant
}

impl CallMixer {
    pub fn mix_frame(&mut self) {
        // For each participant, mix all OTHER participants
        for (participant, output) in &mut self.outputs {
            let mut mix = [0.0f32; FRAME_SIZE];
            for input in &self.inputs {
                if input.owner != *participant {
                    // Accumulate into mix buffer
                    self.accumulate(*input, &mut mix);
                }
            }
            // Write to output handle's buffer
            output.write(&mix);
        }
    }
}
```

**Mix-minus:** Each participant hears everyone EXCEPT themselves. This prevents echo and is standard for all conferencing systems.

---

## AI Voice Injection

AI participants don't have microphones. They inject audio via TTS:

```rust
pub struct AIParticipant {
    participant: ParticipantHandle,
    tts_stream: AudioStreamHandle,  // TTS output treated like any other stream
    voice_config: VoiceConfig,
}

impl AIParticipant {
    pub fn speak(&mut self, text: &str) {
        // TTS generates audio directly into the stream handle's buffer
        // NO copying through JavaScript
        self.tts_engine.synthesize_into(text, &mut self.tts_stream);
    }
}
```

The mixer sees AI audio streams identically to human mic streams.

---

## Command Buffer Pattern

**Problem:** Synchronous RPC for each action = latency, no batching

**Solution:** Buffer commands, submit atomically, execute on streaming thread

```rust
pub enum CallCommand {
    Join { call: CallHandle, user_id: UUID },
    Leave { call: CallHandle, user_id: UUID },
    SetAudioInput { participant: ParticipantHandle, stream: AudioStreamHandle },
    SetAudioOutput { participant: ParticipantHandle, mix: AudioMixHandle },
    Mute { participant: ParticipantHandle },
    Unmute { participant: ParticipantHandle },
    InjectTTS { participant: ParticipantHandle, text: String },
    // Video commands...
}

pub struct CallCommandBuffer {
    commands: Vec<CallCommand>,
}

impl CallCommandBuffer {
    pub fn submit(self) -> CommandBufferHandle {
        // Send to streaming thread
        // Returns handle to check completion
    }
}
```

**TypeScript side:**
```typescript
// Batch multiple operations
const buffer = CallCommandBuffer.create();
buffer.push({ type: 'join', callId, userId });
buffer.push({ type: 'setAudioInput', participantId, streamHandle });
buffer.push({ type: 'unmute', participantId });
const receipt = await buffer.submit();
```

---

## Video Architecture (Future)

Same principles:
- VideoFrameHandle points to GPU texture or shared memory
- Encoder/decoder in Rust (via ffmpeg or WebCodecs bridge)
- Never copy pixels through JS
- SFU (Selective Forwarding Unit) pattern for multi-party

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Camera     â”‚   â”‚ Screen     â”‚   â”‚ Game       â”‚
â”‚ Capture    â”‚   â”‚ Share      â”‚   â”‚ Stream     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚                â”‚
      â–¼                â–¼                â–¼
   VideoFrameHandle (all point to native buffers)
      â”‚                â”‚                â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Video Router   â”‚
              â”‚ (SFU pattern)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼             â–¼             â–¼
    Participant A  Participant B  Participant C
    (receives B,C) (receives A,C) (receives A,B)
```

---

## Commands (AI-Executable)

### Call Lifecycle
```
collaboration/call/start     --participants="helper,teacher"
collaboration/call/join      --callId="..."
collaboration/call/leave     --callId="..."
collaboration/call/end       --callId="..."  (owner only)
collaboration/call/list      --roomId="..." | --active=true
```

### Participant Management
```
collaboration/call/invite    --callId="..." --userId="..."
collaboration/call/kick      --callId="..." --userId="..."
collaboration/call/participants --callId="..."
```

### Audio Control
```
collaboration/call/mute      --callId="..."
collaboration/call/unmute    --callId="..."
collaboration/call/speak     --callId="..." --text="Hello"  (AI TTS)
collaboration/call/volume    --callId="..." --userId="..." --level=0.8
```

### Video Control
```
collaboration/call/camera    --callId="..." --enabled=true
collaboration/call/screen-share --callId="..." --enabled=true
collaboration/call/video-layout --callId="..." --layout="grid|spotlight|strip"
```

### Status/Signaling
```
collaboration/call/raise-hand  --callId="..."
collaboration/call/react       --callId="..." --emoji="ğŸ‘"
collaboration/call/status      --callId="..."  (who's muted, sharing, etc.)
```

---

## Module Structure

```
workers/streaming-core/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs
â”‚   â”œâ”€â”€ handles.rs           # Handle types and pools
â”‚   â”œâ”€â”€ command_buffer.rs    # Command buffer impl
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ capture.rs       # Mic input (SharedArrayBuffer)
â”‚   â”‚   â”œâ”€â”€ playback.rs      # Speaker output
â”‚   â”‚   â”œâ”€â”€ mixer.rs         # Multi-party mixing
â”‚   â”‚   â”œâ”€â”€ stream.rs        # AudioStreamHandle impl
â”‚   â”‚   â””â”€â”€ tts.rs           # AI voice synthesis
â”‚   â”œâ”€â”€ video/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ capture.rs       # Camera/screen capture
â”‚   â”‚   â”œâ”€â”€ encoder.rs       # H.264/VP9 encoding
â”‚   â”‚   â”œâ”€â”€ decoder.rs       # Decoding
â”‚   â”‚   â””â”€â”€ router.rs        # SFU routing
â”‚   â””â”€â”€ transport/
â”‚       â”œâ”€â”€ mod.rs
â”‚       â”œâ”€â”€ webrtc.rs        # WebRTC data channels
â”‚       â””â”€â”€ websocket.rs     # Fallback transport

commands/collaboration/call/
â”œâ”€â”€ start/                   # Create call + join
â”œâ”€â”€ join/                    # Join existing
â”œâ”€â”€ leave/                   # Leave call
â”œâ”€â”€ end/                     # End call (owner)
â”œâ”€â”€ invite/                  # Add participant
â”œâ”€â”€ kick/                    # Remove participant
â”œâ”€â”€ mute/                    # Mute self
â”œâ”€â”€ unmute/                  # Unmute self
â”œâ”€â”€ speak/                   # AI TTS injection
â”œâ”€â”€ camera/                  # Toggle video
â”œâ”€â”€ screen-share/            # Toggle screen share
â”œâ”€â”€ participants/            # List participants
â”œâ”€â”€ status/                  # Call status
â””â”€â”€ README.md

widgets/call/
â”œâ”€â”€ CallWidget.ts            # Full video grid view
â”œâ”€â”€ CallBarWidget.ts         # Minimal overlay bar
â”œâ”€â”€ CallControlsWidget.ts    # Mic/cam/share buttons
â””â”€â”€ ParticipantTileWidget.ts # Individual participant tile

system/call/
â”œâ”€â”€ CallManager.ts           # State machine, handle bookkeeping
â”œâ”€â”€ CallEntity.ts            # Database entity (renamed from LiveSession)
â”œâ”€â”€ CallEvents.ts            # Event types
â””â”€â”€ CallHandles.ts           # TypeScript handle wrappers
```

---

## Testing Strategy

### Unit Tests (No audio hardware)
- Handle pool allocation/deallocation
- Command buffer serialization
- Mix-minus algorithm (synthetic inputs)
- State machine transitions

### Integration Tests (Loopback)
- Capture â†’ immediate playback (loopback)
- Rust worker communication
- Handle lifecycle across JSâ†”Rust boundary

### System Tests (Multiple participants)
- Two browser tabs in same call
- AI participant joins and speaks
- Network simulation (latency, packet loss)

### Performance Tests
- Audio latency (target: <50ms end-to-end)
- CPU usage with N participants
- Memory usage (no leaks over time)
- Handle pool exhaustion recovery

---

## Implementation Phases

### Phase 1: Rename + Foundation
- [x] Rename LiveSession â†’ Call (CallEntity, CallParticipant, CallStatus)
- [x] Update EntityRegistry to use CallEntity
- [x] Update command types to use CallEntity imports
- [ ] Create streaming-core Rust worker skeleton
- [ ] Define handle types in Rust
- [ ] SharedArrayBuffer setup between browser â†” Rust

### Phase 2: Audio Capture
- [ ] AudioWorklet capture processor
- [ ] Ring buffer shared memory
- [ ] Rust worker reads from shared buffer
- [ ] AudioStreamHandle creation

### Phase 3: Audio Playback
- [ ] Rust worker writes to output buffer
- [ ] AudioWorklet playback processor
- [ ] Loopback test (mic â†’ speaker)

### Phase 4: Mixing
- [ ] Multi-stream mixer in Rust
- [ ] Mix-minus per participant
- [ ] Two-participant call test

### Phase 5: AI Voice
- [ ] TTS integration in Rust (or call external service)
- [ ] AI participant speaks into call
- [ ] speak command

### Phase 6: Transport
- [ ] WebSocket transport for audio packets
- [ ] Server-side relay
- [ ] Multi-device test

### Phase 7: Video (Future)
- [ ] Video capture handles
- [ ] Encoding/decoding
- [ ] SFU routing

### Phase 8: WebRTC (Optimization)
- [ ] P2P when possible
- [ ] TURN/STUN for NAT traversal
- [ ] Quality adaptation

---

## Open Questions

1. **TTS engine**: Run in Rust (Piper/Coqui) or call external API (ElevenLabs)?
2. **WebRTC vs WebSocket**: Start with WS for simplicity, add WebRTC later?
3. **Video codecs**: VP9 (royalty-free) vs H.264 (hardware support)?
4. **Game streaming**: Capture game window? OBS-style? Direct GPU access?

---

## References

- [bgfx](https://github.com/bkaradzic/bgfx) - Handle-based graphics architecture
- [WebCodecs API](https://developer.mozilla.org/en-US/docs/Web/API/WebCodecs_API) - Browser video encoding
- [AudioWorklet](https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet) - Low-latency audio processing
- [SharedArrayBuffer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer) - Zero-copy browserâ†”worker
