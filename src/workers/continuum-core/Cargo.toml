[package]
name = "continuum-core"
edition.workspace = true
version.workspace = true
authors.workspace = true

[lib]
crate-type = ["cdylib", "rlib"]  # cdylib for FFI, rlib for other Rust

[[bin]]
name = "continuum-core-server"
path = "src/main.rs"

[dependencies]
tokio.workspace = true
serde.workspace = true
serde_json.workspace = true
uuid.workspace = true
reqwest = { version = "0.12", features = ["json"] }
thiserror.workspace = true
dashmap = "6.1"  # Lock-free concurrent HashMap
base64 = "0.22"  # Base64 encoding for audio data
async-trait.workspace = true
chrono.workspace = true
parking_lot.workspace = true
tokio-stream.workspace = true

# Voice processing dependencies
tokio-tungstenite.workspace = true  # WebSocket server for voice calls
futures-util.workspace = true
futures = "0.3"  # For VAD block_on in audio thread
hound = "3.5"  # WAV file reading/writing
once_cell.workspace = true
rubato = "0.15"  # High-quality audio resampling
whisper-rs = "0.13"  # Whisper.cpp bindings for STT
ort.workspace = true  # ONNX Runtime for TTS
rayon.workspace = true
ndarray.workspace = true
num_cpus = "1.16"  # CPU count detection
dirs = "5.0"  # User directories for model paths

# Candle ML framework (for local LLM inference + Orpheus TTS)
candle-core.workspace = true
candle-nn.workspace = true  # For VarBuilder
candle-transformers.workspace = true
tokenizers = { workspace = true, features = ["onig"] }

# Pocket-TTS (Kyutai, 100M, Candle-based CPU TTS with voice cloning)
# Uses candle 0.9 (separate from our 0.8) — CPU-only, no Metal flag to avoid conflicts
pocket-tts = { version = "0.6", default-features = false }

# Model loading (for inference module)
safetensors.workspace = true  # Model weight files
hf-hub.workspace = true       # HuggingFace model downloads
half = "2.4"                  # f16/bf16 handling for LoRA
earshot = "0.1"  # Fast VAD (WebRTC-style)
msedge-tts.workspace = true  # Edge-TTS (free Microsoft TTS API)
tracing.workspace = true
tracing-subscriber.workspace = true
rand.workspace = true  # For test audio generation
ts-rs.workspace = true  # TypeScript type generation

# Memory/Hippocampus — pure compute engine (data from TS ORM via IPC)
fastembed.workspace = true      # Inline ONNX embedding (~5ms per embed, no IPC hop)

# Code module — file operations, change tracking, code intelligence
similar = "2.6"                  # Unified diff computation
ignore = "0.4"                   # .gitignore-aware file walking (from ripgrep)
regex = "1"                      # Regex search for code search

# ORM module — database-agnostic storage with adapter traits
rusqlite = { version = "0.32", features = ["bundled"] }  # SQLite adapter

[features]
default = ["metal"]
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal"]
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]

[dev-dependencies]
tokio-test = "0.4"
tempfile = "3"                   # Temp directories for code module tests
