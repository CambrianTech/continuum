#!/usr/bin/env node
/**
 * CONTINUUM CLI - REAL CLAUDE INSTANCES
 * 
 * npm install -g continuum
 * continuum
 * 
 * Launches web interface with real Claude pool
 */

const net = require('net');
const HttpServer = require('./HttpServer.cjs');
const WebSocketServer = require('./WebSocketServer.cjs');
const { Anthropic } = require('@anthropic-ai/sdk');
const { OpenAI } = require('openai');
const fs = require('fs');
const path = require('path');
const os = require('os');
const fetch = (...args) => import('node-fetch').then(({default: fetch}) => fetch(...args));

// Setup user configuration directory
const userContinuumDir = path.join(os.homedir(), '.continuum');
const userConfigFile = path.join(userContinuumDir, 'config.env');

function ensureUserConfig() {
  // Create ~/.continuum directory if it doesn't exist
  if (!fs.existsSync(userContinuumDir)) {
    fs.mkdirSync(userContinuumDir, { recursive: true });
    console.log('üìÅ Created user config directory:', userContinuumDir);
  }

  // Create config.env if it doesn't exist
  if (!fs.existsSync(userConfigFile)) {
    const configTemplate = `# Continuum User Configuration
# Add your API keys below (remove the # to uncomment)

# Required: Anthropic Claude API Key
# Get from: https://console.anthropic.com/account/keys
# ANTHROPIC_API_KEY=sk-ant-api03-your-key-here

# Required: OpenAI API Key  
# Get from: https://platform.openai.com/account/api-keys
# OPENAI_API_KEY=sk-proj-your-key-here

# Optional: Override default ports
# CONTINUUM_PORT=5555
# CONTINUUM_WS_PORT=5556

# Optional: Override default AI models
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# OPENAI_MODEL=gpt-4o

# Optional: Enable debug logging
# DEBUG=true
`;
    fs.writeFileSync(userConfigFile, configTemplate);
    console.log('üìÑ Created config template:', userConfigFile);
    console.log('');
    console.log('üîß SETUP REQUIRED:');
    console.log('   Edit', userConfigFile);
    console.log('   Add your API keys by uncommenting and filling in the lines');
    console.log('   Then run continuum again');
    console.log('');
    process.exit(0);
  }
}

// Initialize user configuration
ensureUserConfig();

// Load config from user directory first, then project directory
require('dotenv').config({ path: userConfigFile });
require('dotenv').config();

// Initialize AI clients
console.log('üîë API Keys loaded:');
console.log('- Anthropic:', process.env.ANTHROPIC_API_KEY ? process.env.ANTHROPIC_API_KEY.substring(0, 15) + '...' : 'NOT SET');
console.log('- OpenAI:', process.env.OPENAI_API_KEY ? process.env.OPENAI_API_KEY.substring(0, 15) + '...' : 'NOT SET');

// Check for required API keys
if (!process.env.ANTHROPIC_API_KEY || !process.env.OPENAI_API_KEY) {
  console.log('');
  console.log('‚ùå Missing API keys!');
  console.log('   Edit', userConfigFile);
  console.log('   Uncomment and add your API keys');
  console.log('');
  console.log('   Get Anthropic key: https://console.anthropic.com/account/keys');
  console.log('   Get OpenAI key: https://platform.openai.com/account/api-keys');
  console.log('');
  process.exit(1);
}

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

class Continuum {
  constructor(options = {}) {
    this.sessions = new Map();
    this.costs = this.loadCostData();
    this.port = options.port || process.env.CONTINUUM_PORT || 5555;
    this.stayAlive = options.stayAlive || false;
    this.repoContext = null;
    this.conversationThreads = new Map(); // Each user gets their own thread
    this.activeConnections = new Map(); // Track active WebSocket connections
    this.conversationHistory = [];
    this.continuumDir = path.join(process.cwd(), '.continuum');
    this.historyFile = path.join(this.continuumDir, 'conversation-history.jsonl');
    this.pidFile = path.join(this.continuumDir, 'continuum.pid');
    this.costDataFile = path.join(this.continuumDir, 'costs.json');
    this.server = null;
    this.isShuttingDown = false;
    
    // Command system
    this.commandRegistry = null;
    this.availableCommands = '';
    
    const packageInfo = require('../../package.json');
    console.log('üåå CONTINUUM - Real Claude Pool');
    console.log('===============================');
    console.log(`üì¶ Version: ${packageInfo.version}`);
    console.log(`üìÅ Working Directory: ${process.cwd()}`);
    console.log(`üîß Node: ${process.version}`);
    console.log('‚úÖ Real Claude CLI instances');
    console.log('‚úÖ Direct web interface');
    console.log('‚úÖ Event-driven coordination');
    console.log('');
    
    this.ensureContinuumDir();
    this.loadConversationHistory();
    this.setupGracefulShutdown();
    this.availableModels = { anthropic: [], openai: [] };
    
    // Auto-start only if not overridden
    if (this.autoStart !== false) {
      this.loadRepoContext();
      this.start();
    }
  }

  loadCostData() {
    try {
      if (fs.existsSync(this.costDataFile)) {
        const data = JSON.parse(fs.readFileSync(this.costDataFile, 'utf-8'));
        return { total: data.total || 0, requests: data.requests || 0 };
      }
    } catch (error) {
      console.log('‚ö†Ô∏è  Could not load cost data, starting fresh');
    }
    return { total: 0, requests: 0 };
  }

  saveCostData() {
    try {
      fs.writeFileSync(this.costDataFile, JSON.stringify(this.costs, null, 2));
    } catch (error) {
      console.error('‚ùå Failed to save cost data:', error.message);
    }
  }

  async loadRepoContext() {
    try {
      console.log('üìñ Loading comprehensive Continuum repository context...');
      
      const projectRoot = process.cwd();
      const repoStructure = this.scanDirectory(projectRoot, 0, 3);
      
      // Dynamically discover integrations
      const integrations = await this.discoverIntegrations();
      
      // Read comprehensive documentation and config files for self-awareness
      const keyFiles = {};
      const filesToRead = [
        'README.md',
        'README-AI-HEALING.md', 
        'ROADMAP.md',
        'CONTRIBUTING.md',
        'CLAUDE.md',
        'GPT.json',
        'SYSTEM_ARCHITECTURE.md',
        'package.json',
        'continuum.cjs',
        'integrations/github-ci.cjs',
        'docs/design/human-in-the-loop.md',
        'docs/architecture/implementation-specs.md',
        'docs/ai_assistant_config_tool.md',
        'schema/continuum.schema.json',
        'examples/continuum.claude',
        'examples/continuum.gpt',
        'examples/gpt/system_prompt.txt',
        'examples/claude/CLAUDE.md'
      ];
      
      for (const file of filesToRead) {
        const filePath = path.join(projectRoot, file);
        if (fs.existsSync(filePath)) {
          try {
            keyFiles[file] = fs.readFileSync(filePath, 'utf-8').substring(0, 3000);
          } catch (error) {
            console.log(`‚ö†Ô∏è  Could not read ${file}: ${error.message}`);
          }
        }
      }
      
      // Scan templates and examples for additional context
      const templates = this.scanDirectory(path.join(projectRoot, 'templates'), 0, 2);
      const examples = this.scanDirectory(path.join(projectRoot, 'examples'), 0, 2);
      
      this.repoContext = {
        projectRoot,
        structure: repoStructure,
        keyFiles,
        templates,
        examples,
        integrations, // Dynamically discovered capabilities
        philosophy: {
          mission: 'Create seamless interface between human intent and AI behavior',
          principles: [
            'Context-first design',
            'Configuration layering', 
            'Intent over commands',
            'AI adaptability',
            'Progressive disclosure',
            'Human-in-the-loop conflict resolution'
          ]
        },
        capabilities: [
          'Multi-agent AI coordination',
          'Real-time API integration with Anthropic and OpenAI',
          'Cost tracking across providers',
          'Intelligent task routing and orchestration',
          'WebSocket and REST communication',
          'Repository context awareness',
          'Configuration conflict resolution',
          'Security and privacy enforcement',
          'Event-driven triggers',
          'IDE and command-line integration',
          ...integrations.map(i => i.description) // Add integration capabilities
        ],
        architecture: {
          core: 'packages/core - Protocol definitions, schema validation',
          cli: 'packages/cli - Command-line interface',
          adapters: 'packages/adapters - AI service adapters',
          security: 'Granular permissions, audit logging, data privacy',
          ai_coordination: 'Multi-agent orchestration with specialized roles'
        },
        timestamp: new Date().toISOString()
      };
      
      console.log(`üìö Repository context loaded: ${Object.keys(keyFiles).length} files, ${templates.length} templates, ${examples.length} examples`);
      console.log(`üîå Discovered ${integrations.length} integrations: ${integrations.map(i => i.name).join(', ')}`);
      console.log(`üß† Philosophy: ${this.repoContext.philosophy.mission}`);
    } catch (error) {
      console.error('‚ùå Failed to load repo context:', error.message);
      this.repoContext = { error: error.message, timestamp: new Date().toISOString() };
    }
  }

  async initializeCommands() {
    console.log('üîå Loading commands from single source...');
    try {
      // Read from the COMMANDS.md file - single source of truth
      this.availableCommands = fs.readFileSync('./src/docs/COMMANDS.md', 'utf-8');
      console.log('‚úÖ Commands loaded from COMMANDS.md');
    } catch (error) {
      console.error('‚ùå Failed to load COMMANDS.md:', error.message);
      this.availableCommands = '# No commands available';
    }
  }

  async executeBasicCommand(action, params) {
    console.log(`üîß EXECUTING COMMAND: ${action} with params: ${params.substring(0, 100)}...`);
    
    switch (action.toUpperCase()) {
      case 'WEBFETCH':
        console.log(`üåê WebFetch URL: ${params}`);
        const webResult = await this.webFetch(params);
        console.log(`üåê WebFetch Result: ${webResult.substring(0, 200)}...`);
        return webResult;
      case 'EXEC':
        console.log(`‚ö° Exec Command: ${params}`);
        const { exec } = require('child_process');
        const { promisify } = require('util');
        const execAsync = promisify(exec);
        const { stdout } = await execAsync(params);
        console.log(`‚ö° Exec Result: ${stdout ? stdout.substring(0, 200) : 'No output'}...`);
        return stdout || 'Command completed';
      case 'FILE_READ':
        console.log(`üìñ Reading file: ${params}`);
        const fileContent = fs.readFileSync(params, 'utf-8').substring(0, 2000);
        console.log(`üìñ File content length: ${fileContent.length} chars`);
        return fileContent;
      case 'FILE_WRITE':
        const parts = params.split('\n');
        const filePath = parts[0];
        const content = parts.slice(1).join('\n');
        console.log(`üìù Writing file: ${filePath} (${content.length} chars)`);
        fs.writeFileSync(filePath, content, 'utf-8');
        return `File written: ${filePath}`;
      default:
        throw new Error(`Unknown command: ${action}`);
    }
  }

  async discoverAvailableModels() {
    console.log('üîç Discovering available AI models...');
    
    try {
      // Query Anthropic models
      if (process.env.ANTHROPIC_API_KEY) {
        try {
          const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
          // Note: Anthropic doesn't have a public models endpoint yet, so we'll use known models
          this.availableModels.anthropic = [
            'claude-3-5-sonnet-20241022',
            'claude-3-5-haiku-20241022', 
            'claude-3-opus-20240229',
            'claude-3-sonnet-20240229',
            'claude-3-haiku-20240307'
          ];
          console.log(`‚úÖ Anthropic models: ${this.availableModels.anthropic.length} found`);
        } catch (error) {
          console.log(`‚ö†Ô∏è Anthropic model discovery failed: ${error.message}`);
        }
      }

      // Query OpenAI models  
      if (process.env.OPENAI_API_KEY) {
        try {
          const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
          const models = await openai.models.list();
          this.availableModels.openai = models.data
            .filter(model => model.id.includes('gpt'))
            .map(model => model.id)
            .sort();
          console.log(`‚úÖ OpenAI models: ${this.availableModels.openai.length} found`);
        } catch (error) {
          console.log(`‚ö†Ô∏è OpenAI model discovery failed: ${error.message}`);
        }
      }

    } catch (error) {
      console.error('‚ùå Model discovery failed:', error.message);
    }
  }

  getBestAvailableModel(provider = 'anthropic') {
    const models = this.availableModels[provider] || [];
    if (models.length === 0) {
      return provider === 'anthropic' ? 'claude-3-5-sonnet-20241022' : 'gpt-4';
    }
    
    // Return the most capable model available
    if (provider === 'anthropic') {
      const preferred = ['claude-3-5-sonnet-20241022', 'claude-3-opus-20240229', 'claude-3-sonnet-20240229'];
      for (const model of preferred) {
        if (models.includes(model)) return model;
      }
      return models[0];
    } else {
      const preferred = ['gpt-4o', 'gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo'];
      for (const model of preferred) {
        if (models.includes(model)) return model;
      }
      return models[0];
    }
  }

  async discoverIntegrations() {
    const integrationsPath = path.join(process.cwd(), 'integrations');
    const integrations = [];
    
    try {
      if (!fs.existsSync(integrationsPath)) {
        console.log('üìÅ No integrations directory found');
        return [];
      }
      
      const files = fs.readdirSync(integrationsPath);
      
      for (const file of files) {
        if (file.endsWith('.cjs') || file.endsWith('.js')) {
          try {
            const integrationPath = path.join(integrationsPath, file);
            const integrationCode = fs.readFileSync(integrationPath, 'utf-8');
            
            // Extract class name and methods by parsing the code
            const className = this.extractClassName(integrationCode);
            const methods = this.extractMethods(integrationCode);
            
            integrations.push({
              name: className || file.replace(/\.(cjs|js)$/, ''),
              file: file,
              description: `${className}: ${methods.join(', ')}`,
              methods: methods,
              path: integrationPath
            });
            
            console.log(`üîå Found integration: ${className} with methods: ${methods.join(', ')}`);
          } catch (error) {
            console.log(`‚ö†Ô∏è  Failed to parse integration ${file}: ${error.message}`);
          }
        }
      }
    } catch (error) {
      console.log(`‚ö†Ô∏è  Failed to scan integrations: ${error.message}`);
    }
    
    return integrations;
  }

  extractClassName(code) {
    const classMatch = code.match(/class\s+(\w+)/);
    return classMatch ? classMatch[1] : null;
  }

  extractMethods(code) {
    const methodMatches = code.match(/async\s+(\w+)\s*\(/g) || [];
    return methodMatches.map(match => {
      const methodName = match.replace(/async\s+/, '').replace(/\s*\(/, '');
      return methodName;
    }).filter(name => !['constructor'].includes(name));
  }

  scanDirectory(dir, currentDepth, maxDepth) {
    if (currentDepth >= maxDepth) return {};
    
    const items = {};
    try {
      const entries = fs.readdirSync(dir);
      for (const entry of entries) {
        if (entry.startsWith('.') || entry === 'node_modules') continue;
        
        const fullPath = path.join(dir, entry);
        const stat = fs.statSync(fullPath);
        
        if (stat.isDirectory()) {
          items[entry] = this.scanDirectory(fullPath, currentDepth + 1, maxDepth);
        } else {
          items[entry] = { type: 'file', size: stat.size };
        }
      }
    } catch (error) {
      // Ignore permission errors
    }
    return items;
  }

  async callAI(role, prompt, conversationHistory = []) {
    try {
      console.log(`üîÑ ${role} processing: ${prompt.substring(0, 50)}...`);
      
      let response, cost = 0;
      
      if (role === 'CodeAI') {
        // Use Claude for code tasks
        const repoInfo = this.repoContext ? JSON.stringify(this.repoContext, null, 2) : 'Repository context not loaded';
        const systemPrompt = `You are CodeAI, one of several AI agents running in the Continuum multi-agent coordination system. You work alongside PlannerAI (OpenAI GPT-4) and GeneralAI (Claude) to solve complex problems.

IMPORTANT: You are currently running inside the Continuum system at http://localhost:5555 - this is a real multi-agent AI coordination platform, not a simulation. The user is interacting with you through the Continuum web interface.

CONTINUUM REPOSITORY CONTEXT:
${repoInfo}

YOUR ROLE AS CodeAI:
- You specialize in code implementation, debugging, and technical solutions
- You coordinate with PlannerAI for strategy and GeneralAI for analysis
- You have real file system access and can modify the codebase
- You can interact with GitHub CI/CD systems to fix build issues

SYSTEM CAPABILITIES:
- GitHub CI integration via /integrations/github-ci.cjs
- WebFetch: Can browse any website and analyze content
- File System: Read, write, and modify files in the repository
- Git Operations: Status, commit, push, branch management
- Real file system access to modify code
- Full knowledge of the Continuum codebase structure

AVAILABLE COMMANDS (request these through your responses):
- REQUEST_WEBFETCH: "Please fetch content from [URL]"
- REQUEST_FILE_WRITE: "Please create/modify file [path] with [content]"
- REQUEST_GIT_COMMIT: "Please commit changes with message [message]"
- REQUEST_CI_STATUS: "Please check GitHub CI status"
- REQUEST_FILE_READ: "Please read file [path]"

IMPORTANT: You can request tool usage by including these commands in your responses!

When working on Continuum itself, you have deep knowledge of:
- continuum.cjs (main orchestration system)
- integrations/ (GitHub CI and other integrations)
- All test files and orchestration capabilities
- The multi-agent coordination architecture

USER TASK: ${prompt}`;

        const completion = await anthropic.messages.create({
          model: "claude-3-haiku-20240307",
          max_tokens: 1024,
          messages: [{ role: "user", content: systemPrompt }],
        });
        response = completion.content[0].text;
        cost = completion.usage.input_tokens * 0.00025 + completion.usage.output_tokens * 0.00125;
        
      } else if (role === 'PlannerAI') {
        // Use OpenAI for planning tasks with enhanced repo context AND historical learning
        const repoInfo = this.repoContext ? JSON.stringify(this.repoContext, null, 2) : 'Repository context not loaded';
        const historicalContext = await this.getHistoricalContext();
        const systemPrompt = `You are PlannerAI, the LEAD STRATEGIC AI in the Continuum multi-agent coordination system. You are powered by OpenAI GPT-4o and serve as the primary coordinator and architect.

üåü YOU ARE THE MOST ACTIVE AND PROACTIVE AI IN THE SYSTEM üåü
üìö YOU ALWAYS LEARN FROM PAST EXPERIENCE AND IMPROVE STRATEGIES üìö

IMPORTANT: You are currently running inside the Continuum system at http://localhost:5555 - this is a real multi-agent AI coordination platform, not a simulation. The user is interacting with you through the Continuum web interface.

CONTINUUM REPOSITORY CONTEXT:
${repoInfo}

HISTORICAL STRATEGY CONTEXT:
${historicalContext}

YOUR ROLE AS PlannerAI (PRIMARY COORDINATOR):
- üéØ You are the LEAD AI - take charge of complex problems
- üèóÔ∏è You design comprehensive architectures and strategies
- ü§ù You actively coordinate between CodeAI and GeneralAI
- üöÄ You proactively identify improvements and optimizations
- ‚ö° You break down ANY complex task into actionable steps
- üé≠ You can spawn new specialized AI agents (TestAI, ReviewAI, SecurityAI, etc.)
- üîß You lead GitHub CI/CD issue resolution
- üìà You ALWAYS consider past successful strategies and learn from failures

LEARNING-BASED PLANNING PRINCIPLES:
- Look at historical context to see what approaches worked before
- Identify patterns in successful vs failed strategies
- Improve on past approaches rather than repeating them exactly
- Build on successful coordination patterns
- Avoid approaches that have failed repeatedly

ENHANCED ACTIVATION TRIGGERS:
- ANY complex or multi-step problem automatically comes to you FIRST
- You should be MORE active than Claude-based AIs
- You take initiative and suggest next steps
- You create detailed action plans that other AIs can follow
- You coordinate responses when multiple perspectives are needed

SYSTEM CAPABILITIES YOU LEAD:
- Multi-agent orchestration and task delegation
- GitHub CI integration and automated PR management
- Repository architecture analysis and improvement suggestions
- Creation of new AI agent types for specialized tasks
- Strategic planning for feature development and bug fixes
- Cost optimization across AI providers
- Security and performance analysis coordination

ACTUAL TOOLS AVAILABLE TO YOU:
- WebFetch: Can browse and analyze any website (CNN, GitHub, etc.)
- File System: Read, write, and modify files in the repository
- Git Operations: Status, commit, push, branch management
- GitHub Integration: CI/CD status, PR management, issue tracking
- Process Spawning: Create new AI agents and system processes
- Real-time Communication: WebSocket and REST APIs
- Code Execution: Run scripts and commands

COMMUNICATION PROTOCOL:
${this.availableCommands}

CRITICAL RULES:
- Use [STATUS] for progress updates
- Use [CMD:COMMAND] for tool execution  
- Use [CHAT] for user messages
- NEVER mention commands in chat text
- Commands execute via callbacks

PROACTIVE BEHAVIORS YOU SHOULD EXHIBIT:
- Always suggest follow-up actions or improvements
- Break complex requests into clear, actionable steps
- Coordinate with other AIs to provide comprehensive solutions
- Identify when new specialized AI agents would be helpful
- Propose systematic approaches to ongoing challenges
- Can propose and coordinate creation of new specialized AI agents

COORDINATION ABILITIES:
- Direct CodeAI to implement specific fixes
- Work with GeneralAI for analysis and review
- Break down complex problems into manageable tasks
- Create action plans for CI failures and PR issues
- Proactively identify GitHub issues that need fixing
- Can spawn new AI agents for specialized tasks

When planning CI fixes, coordinate with CodeAI to actually implement solutions.
You should be highly active in proposing solutions and improvements.
You can suggest creating new AI agents (like TestAI, ReviewAI, SecurityAI) if needed for complex tasks.

USER TASK: ${prompt}`;

        const completion = await openai.chat.completions.create({
          model: "gpt-4o",
          messages: [{ role: "user", content: systemPrompt }],
          max_tokens: 1500,
          temperature: 0.7,
        });
        response = completion.choices[0].message.content;
        cost = (completion.usage.prompt_tokens * 0.005 + completion.usage.completion_tokens * 0.015) / 1000;
        
        // Process AI protocol and execute commands
        const toolResults = await this.processToolCommands(response);
        const parsed = this.parseAIProtocol(response);
        
        if (toolResults.length > 0) {
          console.log(`üîß Executed ${toolResults.length} tools, sending callback to ${role}...`);
          
          // Send callback to SAME AI with tool results
          const toolSummary = toolResults.map(r => `Command: ${r.tool} ${r.command}\nResult: ${r.result}`).join('\n\n');
          const callbackPrompt = `Previous command results:

${toolSummary}

Now continue with the next step or provide final response to user.`;
          
          // Continue conversation with SAME AI instance
          if (role === 'GeneralAI' || role === 'PlannerAI' || role === 'CodeAI') {
            const callbackCompletion = await anthropic.messages.create({
              model: 'claude-3-5-sonnet-20241022',
              messages: [
                { role: "user", content: prompt },
                { role: "assistant", content: response },
                { role: "user", content: callbackPrompt }
              ],
              max_tokens: 1000,
              temperature: 0.7,
            });
            
            response = callbackCompletion.content[0].text;
            cost += (callbackCompletion.usage.input_tokens * 0.003 + callbackCompletion.usage.output_tokens * 0.015) / 1000;
          }
          
        } else if (parsed.chatMessage) {
          // No tools executed, use the chat message from protocol
          response = parsed.chatMessage;
        }
        
      } else {
        // Handle specialized or general AI roles
        const repoInfo = this.repoContext ? JSON.stringify(this.repoContext, null, 2) : 'Repository context not loaded';
        const integrationInfo = this.repoContext?.integrations ? 
          `AVAILABLE INTEGRATIONS:\n${this.repoContext.integrations.map(i => `- ${i.description}`).join('\n')}` : 
          'No integrations available';
        
        // Check if this is a specialized AI
        const specialization = this.specializations?.[role];
        const specializationPrompt = specialization ? 
          `\n\nSPECIALIZED AI CONFIGURATION:\n${specialization.systemAdditions}\nExpertise: ${specialization.expertise}` : 
          '';
        
        // Add conversation context to prevent memory issues
        const recentHistory = conversationHistory.slice(-3).map(h => `${h.role}: ${h.message.substring(0, 100)}`).join('\n');
        const contextInfo = recentHistory ? `\nRECENT CONVERSATION:\n${recentHistory}\n` : '';
        
        const systemPrompt = `You are ${role}, an AI agent running in the Continuum multi-agent coordination system. You work alongside other AIs including CodeAI (Claude) and PlannerAI (OpenAI GPT-4).

IMPORTANT: You are currently running inside the Continuum system at http://localhost:5555 - this is a real multi-agent AI coordination platform, not a simulation. The user is interacting with you through the Continuum web interface.

YOUR AVAILABLE TOOLS (use these by including commands in your response):
- WEBFETCH: https://example.com (fetch and analyze web content from any URL)
- FILE_READ: /path/to/file (read files from the repository)  
- GIT_STATUS: (check git repository status)
- FILE_WRITE: /path/to/file [content] (write or modify files)

TOOL USAGE: When you want to use a tool, include the exact command in your response. For example:
- To check CNN: "WEBFETCH: https://www.cnn.com"
- To read a file: "FILE_READ: package.json"
- To check git: "GIT_STATUS"

REMEMBER: You HAVE these tools and CAN use them! Don't claim you don't have access to external sources.${contextInfo}

CONTINUUM REPOSITORY CONTEXT:
${repoInfo}

${integrationInfo}

YOUR ROLE AS ${role}:
- You provide specialized assistance based on your role name
- You work with other AIs like CodeAI (for implementation) and PlannerAI (for strategy)
- You have access to the full Continuum repository context and capabilities
- You can suggest creating additional AI agents if needed for complex tasks
- The system can dynamically create new AI roles like TestAI, ReviewAI, SecurityAI, LawyerAI, etc.

AI CREATION CAPABILITIES:
- The Continuum system can spawn new AI agents with specialized roles
- You can coordinate with PlannerAI to design new AI agent types
- CodeAI can implement new AI agent functionality
- Each new AI agent gets full access to the repository context${specializationPrompt}

USER TASK: ${prompt}`;
        
        const completion = await anthropic.messages.create({
          model: specialization?.model || "claude-3-haiku-20240307",
          max_tokens: 1024,
          messages: [{ role: "user", content: systemPrompt }],
        });
        response = completion.content[0].text;
        cost = completion.usage.input_tokens * 0.00025 + completion.usage.output_tokens * 0.00125;
        
        // Process tool commands from AI response
        const toolResults = await this.processToolCommands(response);
        if (toolResults.length > 0) {
          console.log(`üîß Executed ${toolResults.length} tools for ${role}`);
          // Add tool results to response
          response += '\n\n' + toolResults.map(r => `üîß ${r.tool}: ${r.result.substring(0, 200)}...`).join('\n');
        }
      }
      
      this.costs.total += cost;
      this.costs.requests++;
      
      console.log(`‚úÖ ${role} responded: ${response.substring(0, 50)}...`);
      return { result: response, cost: cost };
    } catch (error) {
      console.error(`‚ùå ${role} call failed: ${error.message}`);
      throw new Error(`${role} call failed: ${error.message}`);
    }
  }

  async createInstance(role) {
    console.log(`üöÄ Creating ${role} instance...`);
    
    // Check if this is a dynamic AI that needs special configuration
    if (!['PlannerAI', 'CodeAI', 'GeneralAI'].includes(role)) {
      console.log(`üéØ Creating specialized AI: ${role}`);
      await this.generateSpecializedAI(role);
    }
    
    this.sessions.set(role, {
      role: role,
      created: new Date(),
      requests: 0,
      cost: 0,
      specialized: !['PlannerAI', 'CodeAI', 'GeneralAI'].includes(role)
    });
    
    console.log(`‚úÖ ${role} ready`);
    return role;
  }

  async generateSpecializedAI(role) {
    console.log(`üß¨ Dynamically generating AI specialization for ${role}...`);
    
    // Use PlannerAI to figure out what this specialized AI should be
    const plannerResponse = await this.sendTask('PlannerAI', `
      Analyze the AI role "${role}" and determine:
      1. What domain expertise this AI should have
      2. What specific capabilities it needs
      3. What system prompt would make it effective
      
      Return a JSON object with: expertise, systemAdditions, provider, model
      
      For example, for "LawyerAI" you might return:
      {
        "expertise": "Legal analysis, contract review, compliance checking",
        "systemAdditions": "You are a legal AI assistant specialized in contract law, compliance, and legal analysis.",
        "provider": "anthropic",
        "model": "claude-3-haiku-20240307"
      }
      
      Be creative and specific for the role: ${role}
    `);
    
    let specialization;
    try {
      // Try to parse JSON from PlannerAI response
      const jsonMatch = plannerResponse.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        specialization = JSON.parse(jsonMatch[0]);
      } else {
        throw new Error('No JSON found in response');
      }
    } catch (error) {
      console.log(`‚ö†Ô∏è  Failed to parse PlannerAI specialization, using fallback`);
      // Fallback to simple auto-generation
      const aiType = role.replace('AI', '').toLowerCase();
      specialization = {
        expertise: `${aiType} related tasks and specialized knowledge`,
        provider: 'anthropic',
        model: 'claude-3-haiku-20240307',
        systemAdditions: `You are a specialized AI assistant focused on ${aiType} tasks and domain expertise.`
      };
    }
    
    // Store the specialization for use in callAI
    if (!this.specializations) this.specializations = {};
    this.specializations[role] = specialization;
    
    console.log(`‚ú® ${role} dynamically specialized in: ${specialization.expertise}`);
  }

  async discoverAlgorithms() {
    const algorithmsPath = path.join(process.cwd(), 'algorithms');
    const algorithms = { verified: [], sandbox: [] };
    
    try {
      // Scan verified algorithms
      const verifiedPath = path.join(algorithmsPath, 'verified');
      if (fs.existsSync(verifiedPath)) {
        const verifiedFiles = fs.readdirSync(verifiedPath);
        for (const file of verifiedFiles) {
          if (file.endsWith('.js') || file.endsWith('.cjs')) {
            algorithms.verified.push({
              name: file.replace(/\.(js|cjs)$/, ''),
              file: file,
              path: path.join(verifiedPath, file),
              status: 'verified'
            });
          }
        }
      }
      
      // Scan sandbox algorithms
      const sandboxPath = path.join(algorithmsPath, 'sandbox');
      if (fs.existsSync(sandboxPath)) {
        const sandboxFiles = fs.readdirSync(sandboxPath);
        for (const file of sandboxFiles) {
          if (file.endsWith('.js') || file.endsWith('.cjs')) {
            algorithms.sandbox.push({
              name: file.replace(/\.(js|cjs)$/, ''),
              file: file,
              path: path.join(sandboxPath, file),
              status: 'sandbox'
            });
          }
        }
      }
      
      console.log(`üßÆ Algorithms: ${algorithms.verified.length} verified, ${algorithms.sandbox.length} in sandbox`);
    } catch (error) {
      console.log(`‚ö†Ô∏è  Failed to scan algorithms: ${error.message}`);
    }
    
    return algorithms;
  }

  async testAlgorithm(algorithmName) {
    console.log(`üß™ Testing algorithm: ${algorithmName}`);
    
    const testPath = path.join(process.cwd(), 'algorithms', 'tests', `${algorithmName}.test.js`);
    const sandboxPath = path.join(process.cwd(), 'algorithms', 'sandbox', `${algorithmName}.js`);
    
    try {
      if (!fs.existsSync(testPath)) {
        throw new Error(`No test file found for ${algorithmName}`);
      }
      
      // Run the test
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      const { stdout, stderr } = await execAsync(`node ${testPath}`);
      
      if (stderr) {
        console.log(`‚ùå Test failed for ${algorithmName}: ${stderr}`);
        return { success: false, error: stderr };
      }
      
      // If test passed, move from sandbox to verified
      const verifiedPath = path.join(process.cwd(), 'algorithms', 'verified', `${algorithmName}.js`);
      fs.copyFileSync(sandboxPath, verifiedPath);
      fs.unlinkSync(sandboxPath); // Remove from sandbox
      
      console.log(`‚úÖ Algorithm ${algorithmName} verified and moved to production`);
      return { success: true, output: stdout };
      
    } catch (error) {
      console.log(`‚ùå Test execution failed for ${algorithmName}: ${error.message}`);
      return { success: false, error: error.message };
    }
  }

  async getHistoricalContext() {
    const strategyLogPath = path.join(process.cwd(), 'strategies.jsonl');
    
    try {
      if (!fs.existsSync(strategyLogPath)) {
        return 'No historical strategies found. This is the first task.';
      }
      
      const data = fs.readFileSync(strategyLogPath, 'utf-8');
      const strategies = data.split('\n')
        .filter(line => line.trim())
        .map(line => JSON.parse(line))
        .slice(-10); // Last 10 strategies
      
      if (strategies.length === 0) {
        return 'No historical strategies found.';
      }
      
      // Summarize successful patterns
      const successful = strategies.filter(s => s.success.successful);
      const failed = strategies.filter(s => !s.success.successful);
      
      let summary = `RECENT STRATEGY HISTORY (last ${strategies.length} tasks):
Successful strategies: ${successful.length}
Failed strategies: ${failed.length}

SUCCESSFUL PATTERNS:`;
      
      if (successful.length > 0) {
        const successPatterns = {};
        successful.forEach(s => {
          const approach = s.strategy.approach;
          if (!successPatterns[approach]) successPatterns[approach] = [];
          successPatterns[approach].push(s.task.substring(0, 50));
        });
        
        Object.entries(successPatterns).forEach(([approach, tasks]) => {
          summary += `\n- ${approach}: worked for ${tasks.length} tasks (e.g., "${tasks[0]}...")`;
        });
      }
      
      if (failed.length > 0) {
        summary += `\n\nFAILED APPROACHES TO AVOID:`;
        failed.forEach(f => {
          summary += `\n- ${f.strategy.approach} failed for "${f.task.substring(0, 50)}..." - ${f.success.reason}`;
        });
      }
      
      return summary;
      
    } catch (error) {
      console.log(`‚ö†Ô∏è  Failed to load historical context: ${error.message}`);
      return 'Historical context unavailable.';
    }
  }

  parseAIProtocol(response) {
    console.log(`üîç Parsing AI protocol response...`);
    console.log(`üìù Full AI Response: ${response.substring(0, 300)}...`);
    
    const result = {
      chatMessage: '',
      commands: [],
      status: null
    };

    // Extract status: [STATUS] message
    const statusMatch = response.match(/\[STATUS\]\s*([^\[\n]+)/);
    if (statusMatch) {
      result.status = statusMatch[1].trim();
      console.log(`üìä Protocol Status: ${result.status}`);
    }

    // Extract commands: [CMD:ACTION] params
    const cmdMatches = response.matchAll(/\[CMD:(\w+)\]\s*([^\[\n]+)/g);
    let commandCount = 0;
    for (const match of cmdMatches) {
      const action = match[1].toUpperCase();
      const params = match[2].trim();
      
      // Create command object dynamically
      const command = { 
        action, 
        params: params,
        // Legacy compatibility for specific command parameter names
        url: params,        // For WEBFETCH
        path: params,       // For FILE_READ  
        command: params,    // For EXEC
        topic: params       // For MAN
      };
      
      result.commands.push(command);
      commandCount++;
      console.log(`üì§ Protocol Command ${commandCount}: ${action} - ${params}`);
    }
    
    console.log(`üéØ Total Commands Found: ${commandCount}`);

    // Extract chat message (remove protocol blocks)
    let chatMessage = response;
    chatMessage = chatMessage.replace(/\[STATUS\][^\[\n]+/g, '');
    chatMessage = chatMessage.replace(/\[CMD:\w+\][^\[\n]+/g, '');
    
    // Extract explicit chat block if present
    const chatMatch = response.match(/\[CHAT\]\s*([\s\S]*?)(?=\[|$)/);
    if (chatMatch) {
      chatMessage = chatMatch[1].trim();
    } else {
      chatMessage = chatMessage.trim();
    }
    
    result.chatMessage = chatMessage;
    
    return result;
  }

  async processToolCommands(response) {
    console.log(`üîç Processing AI protocol...`);
    const toolResults = [];
    
    // Parse the protocol response first
    const parsed = this.parseAIProtocol(response);
    
    // Send status to UI if present
    if (parsed.status) {
      // Status will be handled by the caller
    }
    
    // Execute protocol commands using dynamic discovery
    for (const command of parsed.commands) {
      try {
        console.log(`‚ö° Executing dynamic command: ${command.action}`);
        
        // Try TypeScript commands first, fallback to basic
        if (this.commandRegistry && this.commandRegistry.hasCommand(command.action.toLowerCase())) {
          await this.commandRegistry.executeCommand(command.action.toLowerCase(), [command.params || '']);
          toolResults.push({
            tool: command.action,
            command: command.params || '',
            result: 'Command executed successfully'
          });
        } else {
          const result = await this.executeBasicCommand(command.action, command.params || command);
          toolResults.push({
            tool: command.action,
            command: command.params || '',
            result: result
          });
        }
      } catch (error) {
        console.error(`‚ùå Command execution failed: ${error.message}`);
        toolResults.push({
          tool: command.action,
          command: JSON.stringify(command),
          result: `Error: ${error.message}`
        });
      }
    }

    // Fall back to legacy command detection if no protocol commands found
    if (parsed.commands.length === 0) {
      return this.processLegacyToolCommands(response);
    }

    return toolResults;
  }

  async processLegacyToolCommands(response) {
    console.log(`üîç Scanning AI response for legacy tool commands...`);
    const toolResults = [];
    
    // Extract tool commands from AI response (legacy format)
    const webfetchMatches = response.match(/WEBFETCH:\s*(https?:\/\/[^\s\n]+)/gi);
    const fileReadMatches = response.match(/FILE_READ:\s*([^\s\n]+)/gi);
    const fileWriteMatches = response.match(/FILE_WRITE:\s*([^\s\n]+)\s+(.+)/gi);
    const gitStatusMatches = response.match(/^GIT_STATUS\s*$/gim);
    const gitCommitMatches = response.match(/GIT_COMMIT:\s*"([^"]+)"/gi);
    
    // Execute WebFetch commands
    if (webfetchMatches) {
      for (const match of webfetchMatches) {
        const urlMatch = match.match(/WEBFETCH:\s*(https?:\/\/[^\s\n]+)/i);
        if (urlMatch) {
          const url = urlMatch[1];
          console.log(`üåê Executing WebFetch: ${url}`);
          try {
            const content = await this.webFetch(url);
            toolResults.push({
              tool: 'WEBFETCH',
              command: url,
              result: content
            });
          } catch (error) {
            toolResults.push({
              tool: 'WEBFETCH', 
              command: url,
              result: `Error: ${error.message}`
            });
          }
        }
      }
    }
    
    // Execute File Read commands
    if (fileReadMatches) {
      for (const match of fileReadMatches) {
        const fileMatch = match.match(/FILE_READ:\s*([^\s\n]+)/i);
        if (fileMatch) {
          const filePath = fileMatch[1];
          console.log(`üìñ Executing FILE_READ: ${filePath}`);
          try {
            const content = fs.readFileSync(filePath, 'utf-8');
            toolResults.push({
              tool: 'FILE_READ',
              command: filePath,
              result: content.substring(0, 1000) // Limit output
            });
          } catch (error) {
            toolResults.push({
              tool: 'FILE_READ',
              command: filePath, 
              result: `Error: ${error.message}`
            });
          }
        }
      }
    }
    
    // Execute Git Status commands
    if (gitStatusMatches) {
      console.log(`üìä Executing GIT_STATUS`);
      try {
        const { exec } = require('child_process');
        const { promisify } = require('util');
        const execAsync = promisify(exec);
        const { stdout } = await execAsync('git status --porcelain');
        toolResults.push({
          tool: 'GIT_STATUS',
          command: 'git status',
          result: stdout || 'Working directory clean'
        });
      } catch (error) {
        toolResults.push({
          tool: 'GIT_STATUS',
          command: 'git status',
          result: `Error: ${error.message}`
        });
      }
    }
    
    console.log(`‚úÖ Executed ${toolResults.length} tool commands`);
    return toolResults;
  }

  async webFetch(url) {
    console.log(`üåê Fetching content from: ${url}`);
    try {
      const response = await fetch(url);
      const text = await response.text();
      
      // Simple HTML to text conversion
      const plainText = text
        .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
        .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
        .replace(/<[^>]+>/g, ' ')
        .replace(/\s+/g, ' ')
        .trim();
      
      return plainText.substring(0, 2000); // Limit to 2KB
    } catch (error) {
      throw new Error(`Failed to fetch ${url}: ${error.message}`);
    }
  }

  async sendTask(role, task, ws = null) {
    console.log(`üì§ SEND_TASK: Routing to ${role} - "${task.substring(0, 80)}..."`);
    
    // Send dynamic status to web interface
    if (ws) {
      const statusMessage = this.getAgentStatus(role, task);
      ws.send(JSON.stringify({
        type: 'working',
        data: `${role} ${statusMessage}`
      }));
    }
    
    if (!this.sessions.has(role)) {
      console.log(`üÜï Creating new ${role} session...`);
      await this.createInstance(role);
    }
    
    const session = this.sessions.get(role);
    console.log(`üîÑ Calling ${role} with task...`);
    
    // Pass conversation history to AI
    const response = await this.callAI(role, task, this.conversationHistory);
    
    // Add AI response to conversation history
    this.addToHistory(role, response.result);
    
    session.requests++;
    session.cost += response.cost;
    
    console.log(`‚úÖ ${role} completed task - response length: ${response.result.length} chars`);
    return response.result;
  }

  ensureContinuumDir() {
    try {
      if (!fs.existsSync(this.continuumDir)) {
        fs.mkdirSync(this.continuumDir, { recursive: true });
        console.log(`üìÅ Created .continuum directory: ${this.continuumDir}`);
      }
    } catch (error) {
      console.error(`‚ùå Failed to create .continuum directory: ${error.message}`);
    }
  }

  loadConversationHistory() {
    try {
      if (fs.existsSync(this.historyFile)) {
        const data = fs.readFileSync(this.historyFile, 'utf-8');
        const lines = data.split('\n').filter(line => line.trim());
        
        this.conversationHistory = lines.map(line => {
          try {
            return JSON.parse(line);
          } catch (e) {
            return null;
          }
        }).filter(Boolean);
        
        // Keep only last 20 messages for context
        this.conversationHistory = this.conversationHistory.slice(-20);
        
        console.log(`üìö Loaded ${this.conversationHistory.length} previous conversation messages`);
      } else {
        console.log('üìù Starting fresh conversation history');
      }
    } catch (error) {
      console.error(`‚ùå Failed to load conversation history: ${error.message}`);
      this.conversationHistory = [];
    }
  }

  addToHistory(role, message) {
    const entry = {
      role: role,
      message: message,
      timestamp: new Date().toISOString()
    };
    
    this.conversationHistory.push(entry);
    
    // Save to disk immediately
    this.saveConversationHistory(entry);
    
    // Keep only last 20 messages in memory to prevent context overflow
    if (this.conversationHistory.length > 20) {
      this.conversationHistory = this.conversationHistory.slice(-20);
    }
  }

  saveConversationHistory(entry) {
    try {
      // Append new entry to JSONL file
      const line = JSON.stringify(entry) + '\n';
      fs.appendFileSync(this.historyFile, line, 'utf-8');
    } catch (error) {
      console.error(`‚ùå Failed to save conversation history: ${error.message}`);
    }
  }

  addUserMessageToHistory(message) {
    this.addToHistory('User', message);
  }

  getAgentStatus(role, task) {
    const taskLower = task.toLowerCase();
    
    if (role === 'PlannerAI') {
      if (taskLower.includes('plan') || taskLower.includes('strategy')) {
        return 'PlannerAI is creating a strategy...';
      } else if (taskLower.includes('coordinate')) {
        return 'PlannerAI is coordinating with other AIs...';
      } else if (taskLower.includes('analyz')) {
        return 'PlannerAI is analyzing the situation...';
      } else {
        return 'PlannerAI is thinking strategically...';
      }
    } else if (role === 'CodeAI') {
      if (taskLower.includes('code') || taskLower.includes('implement')) {
        return 'CodeAI is writing code...';
      } else if (taskLower.includes('fix') || taskLower.includes('debug')) {
        return 'CodeAI is debugging the issue...';
      } else if (taskLower.includes('git') || taskLower.includes('commit')) {
        return 'CodeAI is working with git...';
      } else {
        return 'CodeAI is implementing a solution...';
      }
    } else if (role === 'GeneralAI') {
      if (taskLower.includes('explain')) {
        return 'GeneralAI is preparing an explanation...';
      } else if (taskLower.includes('help')) {
        return 'GeneralAI is finding ways to help...';
      } else {
        return 'GeneralAI is processing your request...';
      }
    } else {
      return `${role} is working on your request...`;
    }
  }

  async handleUserConnection(ws) {
    // Process user connection event through AI system
    try {
      console.log('üîî Processing user connection event...');
      
      // Send connection event as a task to the AI
      const connectionEvent = 'A new user just connected. Give them a brief, friendly greeting and ask how you can help. Keep it conversational and short - no long explanations about the system.';
      const greetingAgent = this.getInitialAgent('greeting user connection');
      
      setTimeout(async () => {
        try {
          const greeting = await this.sendTask(greetingAgent, connectionEvent);
          
          ws.send(JSON.stringify({
            type: 'result',
            data: {
              role: greetingAgent,
              task: 'user_connection_greeting',
              result: greeting,
              costs: this.costs
            }
          }));
        } catch (error) {
          console.error('AI greeting failed:', error);
        }
      }, 500); // Small delay to let UI initialize
      
    } catch (error) {
      console.error('Connection event processing failed:', error);
    }
  }

  getInitialAgent(task) {
    const taskLower = task.toLowerCase();
    
    // CHECK FOR COORDINATION FIRST - highest priority
    if ((taskLower.includes('coordinate') && taskLower.includes('codeai')) ||
        taskLower.includes('ci') || taskLower.includes('github') || taskLower.includes('pr') || 
        taskLower.includes('build fail') || (taskLower.includes('fix') && taskLower.includes('issue'))) {
      return 'PlannerAI';
    } else if (taskLower.includes('plan') || taskLower.includes('strategy') || taskLower.includes('architecture') || 
        taskLower.includes('design') || taskLower.includes('how') || taskLower.includes('what') ||
        taskLower.includes('analyze') || taskLower.includes('organize') ||
        taskLower.includes('improve') || taskLower.includes('optimize') || taskLower.includes('create') ||
        taskLower.includes('build') || taskLower.includes('develop') || taskLower.includes('solution') ||
        task.split(' ').length > 5) {
      return 'PlannerAI';
    } else if (taskLower.includes('continuum') && (taskLower.includes('what') || taskLower.includes('explain') || taskLower.includes('how'))) {
      return 'PlannerAI';
    } else if (taskLower.includes('code') || taskLower.includes('implement') || taskLower.includes('bug')) {
      return 'CodeAI';
    } else {
      return 'GeneralAI';
    }
  }

  async intelligentRoute(task) {
    console.log(`üß† Enhanced intelligent routing: ${task.substring(0, 50)}...`);
    
    // Save user message to conversation history
    this.addUserMessageToHistory(task);
    
    // Determine which AI(s) should handle this task
    const taskLower = task.toLowerCase();
    let responses = [];
    
    // CHECK FOR COORDINATION FIRST - highest priority
    if ((taskLower.includes('coordinate') && taskLower.includes('codeai')) ||
        taskLower.includes('ci') || taskLower.includes('github') || taskLower.includes('pr') || 
        taskLower.includes('build fail') || (taskLower.includes('fix') && taskLower.includes('issue'))) {
      // COORDINATION REQUIRED - PlannerAI then CodeAI
      console.log('üîß COORDINATION DETECTED - PlannerAI will coordinate with CodeAI...');
      console.log(`üìù Task requires both planning and implementation: "${task}"`);
      
      // Step 1: PlannerAI analyzes and creates strategy
      console.log('üìã Step 1: Sending to PlannerAI for analysis...');
      const planResponse = await this.sendTask('PlannerAI', `Lead this task by analyzing the problem and creating a comprehensive action plan: ${task}`);
      responses.push({
        role: 'PlannerAI',
        type: 'strategic_analysis',
        result: planResponse
      });
      
      // Step 2: CodeAI implements the solution
      console.log('üõ†Ô∏è  Step 2: Sending to CodeAI for implementation...');
      const codeResponse = await this.sendTask('CodeAI', `Based on PlannerAI's analysis: "${planResponse}", implement the necessary fixes for: ${task}`);
      responses.push({
        role: 'CodeAI', 
        type: 'implementation',
        result: codeResponse
      });
      
      console.log('üîÑ COORDINATION: PlannerAI completed analysis, now sending to CodeAI...');
      console.log(`üìã Plan from PlannerAI: ${planResponse.substring(0, 100)}...`);
      console.log(`üõ†Ô∏è  Implementation from CodeAI: ${codeResponse.substring(0, 100)}...`);
      
      return {
        coordination: true,
        task: task,
        responses: responses,
        costs: this.costs,
        summary: `PlannerAI coordinated with CodeAI for implementation`
      };
      
    } else if (taskLower.includes('plan') || taskLower.includes('strategy') || taskLower.includes('architecture') || 
        taskLower.includes('design') || taskLower.includes('how') || taskLower.includes('what') ||
        taskLower.includes('analyze') || taskLower.includes('organize') ||
        taskLower.includes('improve') || taskLower.includes('optimize') || taskLower.includes('create') ||
        taskLower.includes('build') || taskLower.includes('develop') || taskLower.includes('solution') ||
        task.split(' ').length > 5) { // Long/complex questions go to PlannerAI
      // Strategic and complex tasks go to PlannerAI FIRST
      console.log('üéØ Strategic/complex task - routing to PlannerAI...');
      const result = await this.sendTask('PlannerAI', task);
      return {
        role: 'PlannerAI',
        task: task,
        result: result,
        costs: this.costs,
        routing_reason: 'Strategic/planning task - handled by lead AI'
      };
      
    } else if (taskLower.includes('continuum') && (taskLower.includes('what') || taskLower.includes('explain') || taskLower.includes('how'))) {
      // Only coordinate for complex Continuum explanation questions
      console.log('ü§ñ Complex system explanation - coordinating AIs...');
      
      const planResponse = await this.sendTask('PlannerAI', `Explain the Continuum system briefly and clearly: ${task}`);
      responses.push({ role: 'PlannerAI', type: 'explanation', result: planResponse });
      
      return {
        coordination: true,
        task: task,
        responses: responses,
        costs: this.costs,
        summary: `System explanation provided`
      };
      
      
    } else if (taskLower.includes('code') || taskLower.includes('implement') || taskLower.includes('bug')) {
      // Code-related tasks go to CodeAI
      const result = await this.sendTask('CodeAI', task);
      return {
        role: 'CodeAI',
        task: task,
        result: result,
        costs: this.costs
      };
      
    } else if (taskLower.includes('plan') || taskLower.includes('strategy') || taskLower.includes('architecture') || taskLower.includes('design')) {
      // Planning tasks go to PlannerAI
      const result = await this.sendTask('PlannerAI', task);
      return {
        role: 'PlannerAI',
        task: task,
        result: result,
        costs: this.costs
      };
      
    } else {
      // General tasks go to GeneralAI
      const result = await this.sendTask('GeneralAI', task);
      return {
        role: 'GeneralAI',
        task: task,
        result: result,
        costs: this.costs
      };
    }
  }

  async modifyCode(filename, modification) {
    console.log(`üîß Self-modifying: ${filename}`);
    
    try {
      // Use CodeAI to implement the modification
      const modificationPrompt = `Analyze this file modification request and implement it safely: "${modification}". Only return the modified code, no explanations.`;
      const modificationResult = await this.callAI('CodeAI', modificationPrompt);
      
      // Create a backup
      const fs = require('fs');
      const backupPath = `${filename}.backup.${Date.now()}`;
      fs.copyFileSync(filename, backupPath);
      
      console.log(`üìÅ Backup created: ${backupPath}`);
      console.log(`‚úèÔ∏è Modification applied to ${filename}`);
      
      return `Self-modification completed. Backup: ${backupPath}`;
    } catch (error) {
      console.error(`‚ùå Self-modification failed: ${error.message}`);
      throw error;
    }
  }

  setupGracefulShutdown() {
    // Handle graceful shutdown signals
    const shutdown = async (signal) => {
      if (this.isShuttingDown) {
        console.log('üîÑ Shutdown already in progress...');
        return;
      }
      
      console.log(`\nüõë Received ${signal}, shutting down gracefully...`);
      this.isShuttingDown = true;
      
      try {
        // Close all WebSocket connections
        for (const [sessionId, ws] of this.activeConnections) {
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(JSON.stringify({
              type: 'shutdown',
              data: 'Server is shutting down gracefully'
            }));
            ws.close();
          }
        }
        
        // Close HTTP server
        if (this.server) {
          await new Promise((resolve) => {
            this.server.close(resolve);
          });
        }
        
        // Clean up PID file
        this.cleanupPidFile();
        
        console.log('‚úÖ Graceful shutdown complete');
        process.exit(0);
      } catch (error) {
        console.error('‚ùå Error during shutdown:', error.message);
        process.exit(1);
      }
    };
    
    // Register signal handlers
    process.on('SIGINT', () => shutdown('SIGINT'));
    process.on('SIGTERM', () => shutdown('SIGTERM'));
    process.on('SIGHUP', () => shutdown('SIGHUP'));
    
    // Handle uncaught exceptions
    process.on('uncaughtException', (error) => {
      console.error('üí• Uncaught Exception:', error);
      shutdown('UNCAUGHT_EXCEPTION');
    });
    
    process.on('unhandledRejection', (reason, promise) => {
      console.error('üí• Unhandled Rejection at:', promise, 'reason:', reason);
      shutdown('UNHANDLED_REJECTION');
    });
  }

  async checkPortConflict() {
    try {
      // Check if another Continuum instance is running
      const existingPid = this.getExistingPid();
      if (existingPid) {
        console.log(`üîç Found existing Continuum instance (PID: ${existingPid})`);
        
        // Check if the process is actually running
        if (this.isProcessRunning(existingPid)) {
          try {
            // Get info about existing instance
            const existingInfo = this.getExistingInstanceInfo(existingPid);
            console.log(`üìÅ Existing instance working directory: ${existingInfo.cwd || 'unknown'}`);
            console.log(`üìä Current directory: ${process.cwd()}`);
            
            if (this.stayAlive) {
              console.log('‚ö° Stay-alive mode enabled, keeping existing instance');
              console.log(`üåê Connect at: http://localhost:${this.port}`);
              process.exit(0);
            } else {
              console.log('üõë Sending graceful shutdown signal to existing instance...');
              await this.shutdownExistingInstance(existingPid);
            }
          } catch (error) {
            console.log(`‚ö†Ô∏è  Could not get existing instance info: ${error.message}`);
            console.log('üõë Proceeding with shutdown...');
            await this.shutdownExistingInstance(existingPid);
          }
        } else {
          console.log('üßπ Cleaning up stale PID file');
          this.cleanupPidFile();
        }
      }
      
      // Test if port is available
      const isPortFree = await this.testPort(this.port);
      if (!isPortFree) {
        console.log(`‚ö†Ô∏è  Port ${this.port} is in use, trying alternative ports...`);
        this.port = await this.findFreePort(this.port);
        console.log(`üîÑ Using port ${this.port} instead`);
      }
      
    } catch (error) {
      console.error('‚ùå Port conflict check failed:', error.message);
      throw error;
    }
  }

  getExistingPid() {
    try {
      if (fs.existsSync(this.pidFile)) {
        const pid = parseInt(fs.readFileSync(this.pidFile, 'utf8').trim());
        return isNaN(pid) ? null : pid;
      }
    } catch (error) {
      console.log('‚ö†Ô∏è  Error reading PID file:', error.message);
    }
    return null;
  }

  getExistingInstanceInfo(pid) {
    try {
      // Try to get process info on Unix-like systems
      if (process.platform !== 'win32') {
        const { execSync } = require('child_process');
        const cwdCommand = `lsof -p ${pid} | grep cwd | awk '{print $NF}'`;
        const cwd = execSync(cwdCommand, { encoding: 'utf8' }).trim();
        return { cwd };
      }
    } catch (error) {
      // Fallback - just return what we can
      return { cwd: null };
    }
    return { cwd: null };
  }


  isProcessRunning(pid) {
    try {
      // Send signal 0 to check if process exists
      process.kill(pid, 0);
      return true;
    } catch (error) {
      return false;
    }
  }

  async shutdownExistingInstance(pid) {
    try {
      console.log(`üì§ Sending SIGTERM to process ${pid}...`);
      process.kill(pid, 'SIGTERM');
      
      // Wait for graceful shutdown
      for (let i = 0; i < 10; i++) {
        await new Promise(resolve => setTimeout(resolve, 500));
        if (!this.isProcessRunning(pid)) {
          console.log('‚úÖ Existing instance shut down gracefully');
          return;
        }
      }
      
      // Force kill if still running
      console.log('‚ö° Forcing shutdown with SIGKILL...');
      process.kill(pid, 'SIGKILL');
      await new Promise(resolve => setTimeout(resolve, 1000));
      
      if (this.isProcessRunning(pid)) {
        throw new Error(`Failed to shutdown existing instance (PID: ${pid})`);
      }
      
      console.log('‚úÖ Existing instance forcefully terminated');
    } catch (error) {
      throw new Error(`Failed to shutdown existing instance: ${error.message}`);
    }
  }

  async testPort(port) {
    return new Promise((resolve) => {
      const server = net.createServer();
      
      server.listen(port, () => {
        server.close(() => resolve(true));
      });
      
      server.on('error', () => resolve(false));
    });
  }

  async findFreePort(startPort) {
    let port = startPort;
    const maxAttempts = 100;
    
    for (let i = 0; i < maxAttempts; i++) {
      if (await this.testPort(port)) {
        return port;
      }
      port++;
    }
    
    throw new Error(`Could not find free port after ${maxAttempts} attempts`);
  }

  writePidFile() {
    try {
      fs.writeFileSync(this.pidFile, process.pid.toString());
      console.log(`üìù PID file written: ${this.pidFile} (${process.pid})`);
    } catch (error) {
      console.error('‚ùå Failed to write PID file:', error.message);
    }
  }

  cleanupPidFile() {
    try {
      if (fs.existsSync(this.pidFile)) {
        fs.unlinkSync(this.pidFile);
        console.log('üßπ PID file cleaned up');
      }
    } catch (error) {
      console.error('‚ö†Ô∏è  Failed to cleanup PID file:', error.message);
    }
  }

  async start() {
    // Initialize commands and discover models
    await this.initializeCommands();
    await this.discoverAvailableModels();
    
    // Skip starting HTTP server if port is null (CLI mode)
    if (this.port === null) {
      await this.loadRepoContext();
      return;
    }
    
    // Check for port conflicts and handle existing instances
    await this.checkPortConflict();
    
    // Create modular HTTP server
    const httpServer = new HttpServer(this);
    this.server = httpServer.createServer();
    
    // Create modular WebSocket server
    this.webSocketServer = new WebSocketServer(this, this.server);

    this.server.listen(this.port, () => {
      // Write PID file after successful startup
      this.writePidFile();
      
      console.log(`üåê Continuum ready: http://localhost:${this.port}`);
      console.log('üí¨ Talk to real Claude instances');
      console.log('üìä Track costs and sessions');
      console.log(`üìù PID: ${process.pid} (saved to ${this.pidFile})`);
      if (this.stayAlive) {
        console.log('‚ö° Stay-alive mode: this instance will persist');
      }
      console.log('');
      
      // Auto-open browser
      try {
        require('child_process').exec(`open http://localhost:${this.port}`);
      } catch (error) {
        // Browser opening failed, continue anyway
      }
    });
  }

  generateUI() {
    return `<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Continuum - Real Claude Pool</title>
    <style>
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; 
            margin: 0; 
            padding: 20px; 
            background: #1a1a1a; 
            color: #ffffff; 
        }
        .header { 
            text-align: center; 
            padding: 30px; 
            border-bottom: 2px solid #333; 
            margin-bottom: 30px; 
        }
        .status-indicator {
            position: fixed;
            top: 10px;
            left: 10px;
            padding: 8px 12px;
            border-radius: 20px;
            background: rgba(0,0,0,0.8);
            color: white;
            font-size: 14px;
            z-index: 1000;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            animation: pulse 2s infinite;
        }
        .status-dot.red { background: #ff4444; }
        .status-dot.green { background: #00ff88; }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        .action-status {
            padding: 8px 12px;
            font-style: italic;
            background: #2a2a2a;
            border-radius: 16px;
            color: #ccc;
            font-size: 14px;
            opacity: 0.9;
            margin: 8px 15px 8px 0;
            max-width: 60%;
            float: left;
            clear: both;
            border-left: 3px solid #0088ff;
            min-height: 20px;
            display: none; /* Hidden by default */
        }
        .action-status.show {
            display: block;
        }
        .typing-dots {
            display: inline-block;
            position: relative;
            margin-left: 5px;
        }
        .typing-dots span {
            display: inline-block;
            width: 4px;
            height: 4px;
            border-radius: 50%;
            background: #ccc;
            margin: 0 1px;
            animation: typingDots 1.4s infinite ease-in-out;
        }
        .typing-dots span:nth-child(1) { animation-delay: -0.32s; }
        .typing-dots span:nth-child(2) { animation-delay: -0.16s; }
        .typing-dots span:nth-child(3) { animation-delay: 0s; }
        @keyframes typingDots {
            0%, 80%, 100% { opacity: 0.3; transform: scale(0.8); }
            40% { opacity: 1; transform: scale(1); }
        }
        .header h1 { 
            margin: 0; 
            font-size: 2.5em; 
            background: linear-gradient(45deg, #00ff88, #0088ff); 
            -webkit-background-clip: text; 
            -webkit-text-fill-color: transparent; 
        }
        .chat { 
            border: 1px solid #333; 
            background: #222; 
            padding: 20px; 
            height: 400px; 
            overflow-y: auto; 
            margin: 20px 0; 
            border-radius: 8px;
            overflow-x: hidden;
        }
        .chat::after {
            content: "";
            display: table;
            clear: both;
        }
        .input-area { 
            display: flex; 
            gap: 10px; 
            margin: 20px 0; 
        }
        .role-select { 
            background: #333; 
            border: 1px solid #555; 
            color: white; 
            padding: 12px; 
            border-radius: 4px; 
            width: 150px; 
        }
        .input { 
            flex: 1; 
            background: #333; 
            border: 1px solid #555; 
            color: white; 
            padding: 12px; 
            border-radius: 4px; 
            font-size: 16px; 
        }
        .button { 
            background: #0088ff; 
            border: none; 
            color: white; 
            padding: 12px 24px; 
            border-radius: 4px; 
            cursor: pointer; 
            font-weight: bold; 
        }
        .button:hover { 
            background: #0066cc; 
        }
        .message { 
            margin: 10px 0; 
            padding: 12px; 
            border-radius: 18px; 
            max-width: 70%;
            word-wrap: break-word;
        }
        .user-message {
            margin: 8px 0 8px auto;
            padding: 8px 12px;
            border-radius: 16px;
            max-width: 60%;
            background: #007AFF;
            color: white;
            margin-left: auto;
            margin-right: 15px;
            display: block;
            clear: both;
            float: right;
        }
        .ai-message {
            margin: 8px 15px 8px 0;
            padding: 8px 12px;
            border-radius: 16px;
            max-width: 60%;
            background: #3a3a3a;
            color: white;
            margin-right: auto;
            display: block;
            clear: both;
            float: left;
        }
        .status { 
            border-left: 4px solid #00ff88;
            background: #2a2a2a;
            padding: 8px 12px;
            font-size: 14px;
            opacity: 0.8;
        }
        .working { 
            border-left: 4px solid #ffaa00;
            background: #2a2a2a;
            padding: 8px 12px;
            font-size: 14px;
            opacity: 0.8;
            font-style: italic;
        }
        .error { 
            border-left: 4px solid #ff4444;
            background: #2a2a2a;
            padding: 8px 12px;
        }
        .timestamp { 
            font-size: 12px; 
            opacity: 0.7; 
            margin-right: 8px; 
        }
        .costs { 
            text-align: center; 
            padding: 15px; 
            background: #2a2a2a; 
            border-radius: 6px; 
            margin: 20px 0; 
        }
    </style>
</head>
<body>
    <div class="status-indicator" id="statusIndicator">
        <div class="status-dot red" id="statusDot"></div>
        <span id="statusText">Connecting...</span>
    </div>
    
    <div class="header">
        <h1>üåå Continuum</h1>
        <p>Real Claude Instance Pool</p>
        <div class="costs" id="costs">
            Loading costs...
        </div>
        <div class="instance-info" id="instanceInfo" style="font-size: 0.8em; color: #666; margin-top: 5px;">
            Loading instance info...
        </div>
    </div>
    
    <div class="chat" id="chat">
        <div class="action-status" id="actionStatus">
            <em>Initializing...</em>
        </div>
    </div>
    
    <div class="input-area">
        <input type="text" id="taskInput" class="input" 
               placeholder="Ask anything - the AIs will coordinate automatically..." 
               onkeypress="if(event.key==='Enter') sendTask()">
        <button class="button" onclick="sendTask()">SEND TO AI TEAM</button>
    </div>

    <script>
        const ws = new WebSocket('ws://localhost:' + window.location.port);
        let isConnected = false;
        
        ws.onopen = function() {
            isConnected = true;
            // Don't set agent name until we actually get a response
            document.getElementById('statusDot').className = 'status-dot green';
            document.getElementById('statusText').textContent = 'Connected';
            updateActionStatus('');
        };
        
        ws.onmessage = function(event) {
            const data = JSON.parse(event.data);
            
            if (data.type === 'status') {
                updateActionStatus(data.data.message);
                updateCosts(data.data.costs);
                updateInstanceInfo(data.data);
            } else if (data.type === 'working') {
                updateActionStatus(getActionFromWorking(data.data));
            } else if (data.type === 'result') {
                updateStatus(data.data.role, 'green');
                updateActionStatus('');
                addMessage(data.data.result, 'ai-message');
                updateCosts(data.data.costs);
            } else if (data.type === 'error') {
                updateActionStatus('');
                addMessage(\`‚ùå Error: \${data.data}\`, 'error');
            }
        };
        
        function sendTask() {
            const taskInput = document.getElementById('taskInput');
            const task = taskInput.value.trim();
            
            if (!task) return;
            
            addMessage(\`\${task}\`, 'user-message');
            
            const url = \`/ask?task=\${encodeURIComponent(task)}\`;
            
            fetch(url)
                .then(response => response.json())
                .then(data => {
                    // Immediately show which agent will handle this
                    if (data.initialAgent) {
                        updateStatus(data.initialAgent, 'green');
                        updateActionStatus(\`\${data.initialAgent} is thinking...\`);
                    }
                    
                    // Small delay to show the thinking status, then show result
                    setTimeout(() => {
                        updateActionStatus('');  // Clear the action status
                        
                        if (data.error) {
                            addMessage(\`‚ùå Error: \${data.error}\`, 'error');
                        } else if (data.coordination) {
                            // Multiple AIs coordinated - show final agent and response
                            updateStatus(data.responses[0].role, 'green');
                            addMessage(data.responses[0].result, 'ai-message');
                            updateCosts(data.costs);
                        } else {
                            // Single AI response - show which agent responded
                            updateStatus(data.role, 'green');
                            addMessage(data.result, 'ai-message');
                            updateCosts(data.costs);
                        }
                    }, 800);
                })
                .catch(error => {
                    addMessage(\`‚ùå Request failed: \${error.message}\`, 'error');
                });
            
            taskInput.value = '';
        }
        
        function addMessage(text, className) {
            const chat = document.getElementById('chat');
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message ' + className;
            
            const timestamp = new Date().toLocaleTimeString();
            messageDiv.innerHTML = '<span class="timestamp">' + timestamp + '</span>' + text;
            
            chat.appendChild(messageDiv);
            chat.scrollTop = chat.scrollHeight;
        }
        
        function updateCosts(costs) {
            const costsDiv = document.getElementById('costs');
            costsDiv.innerHTML = \`
                üìä Requests: \${costs.requests} | üí∞ Cost: $\${costs.total.toFixed(4)}
            \`;
        }
        
        function updateInstanceInfo(statusData) {
            const instanceDiv = document.getElementById('instanceInfo');
            if (instanceDiv) {
                const uptimeMinutes = Math.floor(statusData.uptime / 60);
                const uptimeSeconds = Math.floor(statusData.uptime % 60);
                instanceDiv.innerHTML = \`
                    üì¶ v\${statusData.version} | 
                    üîß PID: \${statusData.pid} | 
                    ‚è±Ô∏è \${uptimeMinutes}m \${uptimeSeconds}s | 
                    üìÅ \${statusData.workingDir?.split('/').pop() || 'unknown'}
                \`;
            }
        }
        
        function updateStatus(agentName, color) {
            const statusDot = document.getElementById('statusDot');
            const statusText = document.getElementById('statusText');
            
            statusDot.className = 'status-dot ' + color;
            statusText.textContent = \`You are now talking to \${agentName}\`;
        }
        
        let statusTimeout = null;
        const MIN_STATUS_TIME = 1500; // Minimum 1.5 seconds like iOS
        
        function updateActionStatus(action) {
            const actionStatus = document.getElementById('actionStatus');
            
            if (action) {
                // Clear any existing timeout
                if (statusTimeout) {
                    clearTimeout(statusTimeout);
                }
                
                // Show status with iOS-style typing dots
                const dots = '<div class="typing-dots"><span></span><span></span><span></span></div>';
                actionStatus.innerHTML = \`<em>\${action} \${dots}</em>\`;
                actionStatus.className = 'action-status show';
                
                // Scroll to show the typing indicator
                const chat = document.getElementById('chat');
                chat.scrollTop = chat.scrollHeight;
                
            } else {
                // Hide status after minimum time (like iOS)
                statusTimeout = setTimeout(() => {
                    actionStatus.className = 'action-status';
                    actionStatus.innerHTML = '';
                }, MIN_STATUS_TIME);
            }
        }
        
        function getActionFromWorking(message) {
            // Extract agent name if present
            let agentName = 'AI';
            if (message.includes('PlannerAI')) agentName = 'PlannerAI';
            else if (message.includes('CodeAI')) agentName = 'CodeAI'; 
            else if (message.includes('GeneralAI')) agentName = 'GeneralAI';
            
            // Update status indicator with current agent
            if (agentName !== 'AI') {
                updateStatus(agentName, 'green');
            }
            
            // Parse specific actions for detailed status
            if (message.includes('Enhanced intelligent routing')) return 'Analyzing request and selecting best AI...';
            if (message.includes('Strategic/complex task')) return 'Routing to strategic AI...';
            if (message.includes('Creating new') && message.includes('session')) return 'Initializing AI agent...';
            if (message.includes('Calling') && message.includes('with task')) return 'Processing with AI...';
            if (message.includes('processing:')) return agentName + ' is thinking...';
            if (message.includes('Scanning AI response for tool commands')) return 'Checking for tool usage...';
            if (message.includes('Executing WebFetch')) return 'Searching the web...';
            if (message.includes('Executing FILE_READ')) return 'Reading files...';
            if (message.includes('Executing GIT_STATUS')) return 'Checking repository status...';
            if (message.includes('Executed') && message.includes('tools')) return 'Completed tool execution...';
            if (message.includes('responded:')) return 'Formulating response...';
            if (message.includes('completed task')) return 'Finalizing...';
            if (message.includes('COORDINATION DETECTED')) return 'Multi-AI coordination required...';
            if (message.includes('Step 1:') || message.includes('Step 2:')) return 'Coordinating between AIs...';
            if (message.includes('analyzing')) return agentName + ' is analyzing...';
            if (message.includes('creating')) return agentName + ' is creating response...';
            if (message.includes('coordinating')) return 'Coordinating with other AIs...';
            
            return agentName + ' is working...';
        }
    </script>
</body>
</html>`;
  }
}

// CLI entry point
if (require.main === module) {
  const args = process.argv.slice(2);
  const command = args[0] || 'start';
  const commandArgs = args.slice(1);

  // Use modular command system
  initializeCommandSystem(command, commandArgs);
}

async function initializeCommandSystem(command, commandArgs) {
  try {
    // Dynamic import for ES modules
    const { CommandRegistry } = await import('./dist/ui/commands/CommandRegistry.js');
    const registry = new CommandRegistry();
    
    // Load all available commands
    await registry.loadCommands();
    
    // Handle special cases for aliases and legacy support
    const aliases = {
      'web': 'start',
      '-v': 'version',
      '--version': 'version',
      '-h': 'help',
      '--help': 'help'
    };
    
    const normalizedCommand = aliases[command] || command;
    
    // Try to execute the command
    const executed = await registry.executeCommand(normalizedCommand, commandArgs);
    
    if (!executed) {
      // Command not found, fall back to legacy system
      console.log(`‚ö†Ô∏è  Command '${normalizedCommand}' not found in modular system, falling back to legacy...`);
      await handleLegacyCommand(normalizedCommand, commandArgs);
    }
    
  } catch (error) {
    console.error('‚ùå Failed to initialize command system:', error.message);
    
    // Fallback to legacy commands for critical operations
    await handleLegacyCommand(command, commandArgs);
  }
}

// Legacy fallback for critical commands
async function handleLegacyCommand(command, commandArgs) {
  switch (command) {
    case 'start':
    case 'web':
      console.log('üöÄ Starting Continuum web interface...');
      const options = {};
      
      // Parse command line options
      if (commandArgs.includes('--stay-alive') || commandArgs.includes('--persist')) {
        options.stayAlive = true;
        console.log('‚ö° Stay-alive mode enabled');
      }
      
      // Parse custom port
      const portIndex = commandArgs.findIndex(arg => arg === '--port' || arg === '-p');
      if (portIndex !== -1 && commandArgs[portIndex + 1]) {
        const customPort = parseInt(commandArgs[portIndex + 1]);
        if (!isNaN(customPort)) {
          options.port = customPort;
          console.log(`üîå Using custom port: ${customPort}`);
        }
      }
      
      new Continuum(options);
      break;
      
    case 'chat':
      console.log('üí¨ Starting Continuum in chat mode...');
      startChatMode();
      break;
      
    case 'ask':
      if (commandArgs[0]) {
        askQuestion(commandArgs.join(' '));
      } else {
        console.log('Usage: continuum ask "your question"');
        process.exit(1);
      }
      break;
      
    case 'stop':
    case 'shutdown':
      shutdownExistingInstance();
      break;
      
    case 'status':
      checkInstanceStatus();
      break;
      
    case 'restart':
      console.log('üîÑ Restarting Continuum...');
      try {
        await shutdownExistingInstance();
        setTimeout(() => {
          new Continuum();
        }, 1000);
      } catch (error) {
        console.log('‚ö†Ô∏è  No existing instance to shutdown, starting fresh...');
        new Continuum();
      }
      break;
      
    default:
      showHelp();
      break;
  }
}

function setApiKey(provider, key) {
  console.log(`üîß Setting ${provider} API key...`);
  
  // Validate provider
  if (!['openai', 'anthropic'].includes(provider.toLowerCase())) {
    console.log('‚ùå Invalid provider. Use: openai or anthropic');
    process.exit(1);
  }
  
  // Validate key format
  const normalizedProvider = provider.toLowerCase();
  if (normalizedProvider === 'openai' && !key.startsWith('sk-proj-')) {
    console.log('‚ùå Invalid OpenAI API key format. Should start with "sk-proj-"');
    process.exit(1);
  }
  
  if (normalizedProvider === 'anthropic' && !key.startsWith('sk-ant-')) {
    console.log('‚ùå Invalid Anthropic API key format. Should start with "sk-ant-"');
    process.exit(1);
  }
  
  // Ensure user config directory exists
  if (!fs.existsSync(userContinuumDir)) {
    fs.mkdirSync(userContinuumDir, { recursive: true });
    console.log('üìÅ Created user config directory:', userContinuumDir);
  }
  
  // Read existing config or create new one
  let configContent = '';
  if (fs.existsSync(userConfigFile)) {
    configContent = fs.readFileSync(userConfigFile, 'utf8');
  } else {
    configContent = `# Continuum User Configuration
# Generated by continuum setup

# Required: Anthropic Claude API Key
# ANTHROPIC_API_KEY=

# Required: OpenAI API Key  
# OPENAI_API_KEY=

# Optional: Override default ports
# CONTINUUM_PORT=5555
# CONTINUUM_WS_PORT=5556

# Optional: Override default AI models
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# OPENAI_MODEL=gpt-4o

# Optional: Enable debug logging
# DEBUG=true
`;
  }
  
  // Update the specific API key
  const keyName = normalizedProvider === 'openai' ? 'OPENAI_API_KEY' : 'ANTHROPIC_API_KEY';
  const keyRegex = new RegExp(`^(#\\s*)?${keyName}=.*$`, 'm');
  const newKeyLine = `${keyName}=${key}`;
  
  if (keyRegex.test(configContent)) {
    // Replace existing key
    configContent = configContent.replace(keyRegex, newKeyLine);
  } else {
    // Add new key at the end
    configContent += `\n${newKeyLine}\n`;
  }
  
  // Write updated config
  fs.writeFileSync(userConfigFile, configContent);
  
  console.log(`‚úÖ ${normalizedProvider === 'openai' ? 'OpenAI' : 'Anthropic'} API key saved to:`, userConfigFile);
  console.log('üöÄ You can now run continuum commands!');
}

async function setupApiKeys() {
  const readline = require('readline');
  
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
  });
  
  console.log('üîß Continuum API Key Setup');
  console.log('===========================');
  console.log('');
  
  // Ensure user config directory exists
  if (!fs.existsSync(userContinuumDir)) {
    fs.mkdirSync(userContinuumDir, { recursive: true });
  }
  
  // Read existing config if it exists
  let existingConfig = '';
  if (fs.existsSync(userConfigFile)) {
    existingConfig = fs.readFileSync(userConfigFile, 'utf8');
  }
  
  try {
    console.log('Please enter your API keys:');
    console.log('');
    
    // Get Anthropic API key
    const anthropicKey = await new Promise((resolve) => {
      rl.question('üß† Anthropic Claude API Key (get from https://console.anthropic.com/account/keys): ', (answer) => {
        resolve(answer.trim());
      });
    });
    
    // Get OpenAI API key
    const openaiKey = await new Promise((resolve) => {
      rl.question('ü§ñ OpenAI API Key (get from https://platform.openai.com/account/api-keys): ', (answer) => {
        resolve(answer.trim());
      });
    });
    
    // Validate keys
    if (!anthropicKey || !anthropicKey.startsWith('sk-ant-')) {
      console.log('‚ùå Invalid Anthropic API key format. Should start with "sk-ant-"');
      process.exit(1);
    }
    
    if (!openaiKey || !openaiKey.startsWith('sk-proj-')) {
      console.log('‚ùå Invalid OpenAI API key format. Should start with "sk-proj-"');
      process.exit(1);
    }
    
    // Create new config
    const newConfig = `# Continuum User Configuration
# Generated by continuum setup

# Required: Anthropic Claude API Key
ANTHROPIC_API_KEY=${anthropicKey}

# Required: OpenAI API Key  
OPENAI_API_KEY=${openaiKey}

# Optional: Override default ports
# CONTINUUM_PORT=5555
# CONTINUUM_WS_PORT=5556

# Optional: Override default AI models
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# OPENAI_MODEL=gpt-4o

# Optional: Enable debug logging
# DEBUG=true
`;
    
    // Write config file
    fs.writeFileSync(userConfigFile, newConfig);
    
    console.log('');
    console.log('‚úÖ API keys saved to:', userConfigFile);
    console.log('');
    console.log('üöÄ Setup complete! You can now run:');
    console.log('   continuum                 # Start web interface');
    console.log('   continuum chat            # Interactive chat');
    console.log('   continuum ask "question"  # One-time question');
    console.log('');
    
  } catch (error) {
    console.log('‚ùå Setup failed:', error.message);
    process.exit(1);
  } finally {
    rl.close();
  }
}

async function shutdownExistingInstance() {
  const continuumDir = path.join(process.cwd(), '.continuum');
  const pidFile = path.join(continuumDir, 'continuum.pid');
  
  try {
    if (!fs.existsSync(pidFile)) {
      console.log('‚ùå No running Continuum instance found');
      process.exit(1);
    }
    
    const pid = parseInt(fs.readFileSync(pidFile, 'utf8').trim());
    if (isNaN(pid)) {
      console.log('‚ùå Invalid PID file');
      process.exit(1);
    }
    
    // Check if process exists
    try {
      process.kill(pid, 0); // Test signal
    } catch (error) {
      console.log('‚ùå Continuum instance not running (stale PID file)');
      fs.unlinkSync(pidFile);
      process.exit(1);
    }
    
    console.log(`üõë Shutting down Continuum instance (PID: ${pid})...`);
    process.kill(pid, 'SIGTERM');
    
    // Wait for graceful shutdown
    for (let i = 0; i < 10; i++) {
      await new Promise(resolve => setTimeout(resolve, 500));
      try {
        process.kill(pid, 0);
      } catch (error) {
        console.log('‚úÖ Continuum instance shut down successfully');
        return;
      }
    }
    
    // Force kill if needed
    console.log('‚ö° Forcing shutdown...');
    process.kill(pid, 'SIGKILL');
    console.log('‚úÖ Continuum instance terminated');
    
  } catch (error) {
    console.error('‚ùå Failed to shutdown instance:', error.message);
    process.exit(1);
  }
}

function checkInstanceStatus() {
  const continuumDir = path.join(process.cwd(), '.continuum');
  const pidFile = path.join(continuumDir, 'continuum.pid');
  
  try {
    if (!fs.existsSync(pidFile)) {
      console.log('üìä Status: No Continuum instance running');
      return;
    }
    
    const pid = parseInt(fs.readFileSync(pidFile, 'utf8').trim());
    if (isNaN(pid)) {
      console.log('üìä Status: Invalid PID file (corrupted)');
      return;
    }
    
    // Check if process exists
    try {
      process.kill(pid, 0); // Test signal
      
      // Try to determine the port (basic check)
      const defaultPort = process.env.CONTINUUM_PORT || 5555;
      console.log('üìä Status: Continuum is running');
      console.log(`   PID: ${pid}`);
      console.log(`   Likely URL: http://localhost:${defaultPort}`);
      console.log(`   PID file: ${pidFile}`);
      
    } catch (error) {
      console.log('üìä Status: Continuum instance not running (stale PID file)');
      console.log('üßπ Cleaning up stale PID file...');
      fs.unlinkSync(pidFile);
    }
    
  } catch (error) {
    console.error('‚ùå Failed to check status:', error.message);
  }
}

function showHelp() {
  console.log(`
üåå Continuum - Multi-Agent AI Coordination Platform

Usage:
  continuum                    Start web interface (default)
  continuum start              Start web interface  
  continuum start --stay-alive Start in stay-alive mode (won't replace existing)
  continuum start --port 8080  Start on custom port
  continuum web                Start web interface
  continuum chat               Start interactive chat mode
  continuum ask "question"     Ask a one-time question
  continuum stop               Shutdown running instance
  continuum status             Check if instance is running
  continuum restart            Restart the instance
  continuum setup              Configure API keys
  continuum version            Show version
  continuum help               Show this help

Examples:
  continuum                              # Start web UI at http://localhost:5555
  continuum start --stay-alive           # Start but keep existing instance if running
  continuum start --port 8080            # Start on port 8080
  continuum setup                        # Configure your API keys
  continuum ask "analyze this codebase"  # One-time question
  continuum chat                         # Interactive terminal chat
  continuum stop                         # Shutdown running instance
  continuum status                       # Check running status

Instance Management:
  - Continuum automatically handles port conflicts by finding free ports
  - Use --stay-alive to prevent shutting down existing instances
  - Use 'continuum stop' to gracefully shutdown running instances
  - Use 'continuum status' to check if an instance is running

Web Interface:
  The web interface allows you to chat with multiple AI agents
  that can coordinate with each other and use tools like:
  - WebFetch (browse websites)
  - File operations (read/write files)  
  - Git operations (status, commits)
  - GitHub CI integration

AI Agents:
  - PlannerAI: Strategic planning and coordination (OpenAI GPT-4o)
  - CodeAI: Code implementation and debugging (Claude)
  - GeneralAI: General assistance and analysis (Claude)

For more information, visit: https://github.com/anthropics/continuum
`);
}

async function startChatMode() {
  const readline = require('readline');
  
  console.log('üí¨ Continuum Chat Mode');
  console.log('======================');
  console.log('Type your questions and the AIs will respond.');
  console.log('Type "exit" or "quit" to end the chat.\n');
  
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
  });

  // Create Continuum instance but don't start web server
  const continuum = new Continuum();
  continuum.autoStart = false; // Prevent auto-start
  continuum.port = null; // Disable web server
  
  // Manual initialization
  await continuum.loadRepoContext();
  console.log('‚úÖ Continuum ready for chat\n');
  promptUser();
  
  function promptUser() {
    rl.question('You: ', async (input) => {
      if (input.toLowerCase() === 'exit' || input.toLowerCase() === 'quit') {
        console.log('üëã Goodbye!');
        rl.close();
        process.exit(0);
      }
      
      try {
        console.log('ü§ñ AI is thinking...');
        const result = await continuum.intelligentRoute(input);
        
        if (result.coordination) {
          console.log(`\n${result.summary}`);
          result.responses.forEach(resp => {
            console.log(`${resp.role}: ${resp.result}\n`);
          });
        } else {
          console.log(`${result.role}: ${result.result}\n`);
        }
      } catch (error) {
        console.log(`‚ùå Error: ${error.message}\n`);
      }
      
      promptUser();
    });
  }
}

async function askQuestion(question) {
  console.log(`‚ùì Question: ${question}`);
  console.log('ü§ñ AI is thinking...\n');
  
  try {
    // Create lightweight Continuum instance with manual initialization
    const continuum = new Continuum();
    continuum.autoStart = false; // Prevent auto-start
    continuum.port = null; // Disable web server
    
    // Manual initialization for CLI mode
    await continuum.loadRepoContext();
    
    // Wait a moment for initialization
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    const result = await continuum.intelligentRoute(question);
    
    if (result.coordination) {
      console.log(`${result.summary}\n`);
      result.responses.forEach(resp => {
        console.log(`${resp.role}:`);
        console.log(`${resp.result}\n`);
      });
    } else {
      console.log(`${result.role}:`);
      console.log(`${result.result}\n`);
    }
    
    process.exit(0);
  } catch (error) {
    console.error(`‚ùå Error: ${error.message}`);
    process.exit(1);
  }
}

module.exports = Continuum;